@comment{AAA}

@misc{Abate2020,
  author = {Pietro Abate and Roberto Di Cosmo and Georgios Gousios and Stefano Zacchiroli},
  title = {Dependency Solving Is Still Hard, but We Are Getting Better at It},
  year = {2020},
  eprint = {arXiv:2011.07851},
  howpublished = {2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER), Feb 2020, London, Canada. pp.547-551},
  doi = {10.1109/SANER48275.2020.9054837},
}

@inproceedings{AbouKhalil2022,
  doi = {10.1145/3524842.3528494},
  title = {The general index of software engineering papers},
  booktitle = msr,
  author = {{Abou Khalil}, Zeinab and Zacchiroli, Stefano},
  publisher = {ACM},
  month = may,
  year = {2022},
  abstract = {We introduce the General Index of Software Engineering Papers, a dataset of fulltext-indexed papers from the most prominent scientific venues in the field of Software Engineering. The dataset includes both complete bibliographic information and indexed n-grams (sequence of contiguous words after removal of stopwords and non-words, for a total of 577 276 382 unique n-grams in this release) with length 1 to 5 for 44 581 papers retrieved from 34 venues over the 1971–2020 period. The dataset serves use cases in the field of meta-research, allowing to introspect the output of software engineering research even when access to papers or scholarly search engines is not possible (e.g., due to contractual reasons). The dataset also contributes to making such analyses reproducible and independently verifiable, as opposed to what happens when they are conducted using 3rd-party and non-open scholarly indexing services. The dataset is available as a portable Postgres database dump and released as open data.}
}

@misc{Abreu2022,
  author = {Rui Abreu},
  title = {The Bumpy Road of Taking Automated Debugging to Industry},
  year = {2022},
  eprint = {arXiv:2212.01237},
}

@misc{Ahmed2022,
  author = {Umair Z. Ahmed and Zhiyu Fan and Jooyong Yi and Omar I. Al-Bataineh and Abhik Roychoudhury},
  title = {Verifix: Verified Repair of Programming Assignments},
  year = {2022},
  eprint = {arXiv:2106.16199},
}

@inproceedings{Ait2022,
  doi = {10.1145/3524842.3527941},
  title = {An empirical study on the survival rate of {GitHub} projects},
  booktitle = msr,
  author = {Ait, Adem and Izquierdo, Javier Luis C{\'a}novas and Cabot, Jordi},
  publisher = {ACM},
  month = may,
  year = {2022},
  abstract = {The number of Open Source projects hosted in social coding platforms such as GitHub is constantly growing. However, many of these projects are not regularly maintained and some are even abandoned shortly after they were created. In this paper we analyze early project development dynamics in software projects hosted on GitHub, including their survival rate. To this aim, we collected all 1,127 GitHub repositories from four different ecosystems (i.e., NPM packages, R packages, WordPress plugins and Laravel packages) created in 2016. We stored their activity in a time series database and analyzed their activity evolution along their lifespan, from 2016 to now. Our results reveal that the prototypical development process consists of intensive coding-driven active periods followed by long periods of inactivity. More importantly, we have found that a significant number of projects die in the first year of existence with the survival rate decreasing year after year. In fact, the probability of surviving longer than five years is less than 50\% though some types of projects have better chances of survival.}
}

@misc{AlOmar2022,
  author = {Eman Abdullah AlOmar and Moataz Chouchen and Mohamed Wiem Mkaouer and Ali Ouni},
  title = {Code Review Practices for Refactoring Changes: An Empirical Study on OpenStack},
  year = {2022},
  eprint = {arXiv:2203.14404},
}

@article{Andersen2020,
  doi = {10.1145/3428290},
  url = {https://doi.org/10.1145/3428290},
  year = {2020},
  month = nov,
  publisher = {Association for Computing Machinery ({ACM})},
  volume = {4},
  number = {{OOPSLA}},
  pages = {1--28},
  author = {Leif Andersen and Michael Ballantyne and Matthias Felleisen},
  title = {Adding interactive visual syntax to textual code},
  journal = {Proceedings of the {ACM} on Programming Languages},
  abstract = {Many programming problems call for turning geometrical thoughts into code: tables, hierarchical structures, nests of objects, trees, forests, graphs, and so on. Linear text does not do justice to such thoughts. But, it has been the dominant programming medium for the past and will remain so for the foreseeable future. This paper proposes a novel mechanism for conveniently extending textual programming languages with problem-specific visual syntax. It argues the necessity of this language feature, demonstrates the feasibility with a robust prototype, and sketches a design plan for adapting the idea to other languages.}
}

@misc{Apple2022,
  author = {Jim Apple},
  title = {Stretching Your Data With Taffy Filters},
  year = {2022},
  eprint = {arXiv:2109.01947},
}

@inproceedings{Arteca2022,
  doi = {10.1145/3510003.3510106},
  url = {https://doi.org/10.1145/3510003.3510106},
  year = {2022},
  month = may,
  publisher = {{ACM}},
  author = {Ellen Arteca and Sebastian Harner and Michael Pradel and Frank Tip},
  title = {Nessie},
  booktitle = {Proceedings of the 44th International Conference on Software Engineering}
}

@misc{Asare2022,
  author = {Owura Asare and Meiyappan Nagappan and N. Asokan},
  title = {Is GitHub's Copilot as Bad As Humans at Introducing Vulnerabilities in Code?},
  year = {2022},
  eprint = {arXiv:2204.04741},
}

@comment{BBB}

@misc{Barbosa2022,
  author = {Leonardo Barbosa and Victor Hugo Santiago and Alberto Luiz Oliveira Tavares de Souza and Gustavo Pinto},
  title = {To What Extent Cognitive-Driven Development Improves Code Readability?},
  year = {2022},
  eprint = {arXiv:2206.10655},
}

@inproceedings{Barrak2021,
  doi = {10.1109/saner50967.2021.00046},
  url = {https://doi.org/10.1109/saner50967.2021.00046},
  year = {2021},
  month = mar,
  publisher = {{IEEE}},
  author = {Amine Barrak and Ellis E. Eghan and Bram Adams},
  title = {On the Co-evolution of {ML} Pipelines and Source Code - Empirical Study of {DVC} Projects},
  booktitle = {2021 {IEEE} International Conference on Software Analysis,  Evolution and Reengineering ({SANER})}
}

@article{Baxter2022,
  doi = {10.1002/spe.3120},
  title = {Collaborative experience between scientific software projects using Agile Scrum development},
  author = {Baxter, Amanda L and BenZvi, Segev Y and Bonivento, Walter and Brazier, Adam and Clark, Michael and Coleiro, Alexis and Collom, David and Colomer-Molla, Marta and Cousins, Bryce and Delgado Orellana, Aliwen and Dornic, Damien and Ekimtcov, Vladislav and ElSayed, Shereen and Gallo Rosso, Andrea and Godwin, Patrick and Griswold, Spencer and Habig, Alec and Hill, Remington and Horiuchi, Shunsaku and Howell, D Andrew and Johnson, Margaret W G and Juri{\'c}, Mario and Kneller, James P and Kopec, Abigail and Kopper, Claudio and Kulikovskiy, Vladimir and Lamoureux, Mathieu and Lang, Rafael F and Li, Shengchao and Lincetto, Massimiliano and Lindstrom, Lindy and Linvill, Mark W and McCully, Curtis and Migenda, Jost and Milisavljevic, Danny and Nelson, Spencer and Novoseltseva, Rita and O'Sullivan, Erin and Petravick, Donald and Pointon, Barry W and Raj, Nirmal and Renshaw, Andrew and Rumleskie, Janet and Sonley, Tom and Tapia, Ron and Tseng, Jeffrey C L and Tunnell, Christopher D and Vannoye, Godefroy and Vigorito, Carlo F and Virtue, Clarence J and Weaver, Christopher and Weil, Kathryn E and Winslow, Lindley and Wolski, Rich and Xu, Xun- Jie and Xu, Yiyang and {The SCiMMA and SNEWS Collaborations}},
  journal = {Softw. Pract. Exp.},
  publisher = {Wiley},
  volume = {52},
  number = {10},
  pages = {2077--2096},
  month = oct,
  year = {2022},
  copyright = {http://creativecommons.org/licenses/by-nc/4.0/},
  abstract = {Developing sustainable software for the scientific community requires expertise in software engineering and domain science. This can be challenging due to the unique needs of scientific software, the insufficient resources for software engineering practices in the scientific community, and the complexity of developing for evolving scientific contexts. While open‐source software can partially address these concerns, it can introduce complicating dependencies and delay development. These issues can be reduced if scientists and software developers collaborate. We present a case study wherein scientists from the SuperNova Early Warning System collaborated with software developers from the Scalable Cyberinfrastructure for Multi‐Messenger Astrophysics project. The collaboration addressed the difficulties of open‐source software development, but presented additional risks to each team. For the scientists, there was a concern of relying on external systems and lacking control in the development process. For the developers, there was a risk in supporting a user‐group while maintaining core development. These issues were mitigated by creating a second Agile Scrum framework in parallel with the developers' ongoing Agile Scrum process. This Agile collaboration promoted communication, ensured that the scientists had an active role in development, and allowed the developers to evaluate and implement the scientists' software requirements. The collaboration provided benefits for each group: the scientists actuated their development by using an existing platform, and the developers utilized the scientists' use‐case to improve their systems. This case study suggests that scientists and software developers can avoid scientific computing issues by collaborating and that Agile Scrum methods can address emergent concerns.}
}

@inproceedings{Beasley2022,
  doi = {10.1145/3502718.3524772},
  title = {The impact of remote pair programming in an upper-level {CS} course},
  booktitle = iticse,
  author = {Beasley, Zachariah J and Johnson, Ayesha R},
  publisher = {ACM},
  month = jul,
  year = {2022},
  conference = iticse,
  abstract = {Pair programming is an active learning technique with several benefits to students, including increasing participation and improving outcomes, particularly for female computer science students. However, most of the literature highlights the effects of pair programming in introductory courses, where students have different prior programming experience and thus may experience group issues. This work analyzes the effect of pair programming in an upper-level computer science course, where students have a more consistent background education, particularly in languages learned and coding best practices. Secondly, the effect of remote pair programming on student outcomes is still an open question of increasing importance with the advent of Covid-19. This work utilized split sections with a control and treatment group in a large, public university. In addition to comparing pair programming to individual programming, results were analyzed by modality (remote vs. in person) and by gender, focusing on how pair programming benefits female computer science students in confidence, persistence in the major, and outcomes. We found that pair programming groups scored higher on assignments and exams, that remote pair programming groups performed as well as in person groups, and that female students increased their confidence in asking questions in class and scored 12\% higher in the course when utilizing pair programming.}
}

@misc{Becker2022,
  author = {Brett A. Becker and Paul Denny and James Finnie-Ansley and Andrew Luxton-Reilly and James Prather and Eddie Antonio Santos},
  title = {Programming Is Hard -- Or at Least It Used to Be: Educational Opportunities And Challenges of AI Code Generation},
  year = {2022},
  eprint = {arXiv:2212.01020},
}

@inproceedings{Bendrissou2022,
  doi = {10.1145/3519939.3523716},
  title = {``Synthesizing input grammars'': a replication study},
  booktitle = pldi,
  author = {Bendrissou, Bachir and Gopinath, Rahul and Zeller, Andreas},
  publisher = {ACM},
  month = jun,
  year = {2022},
  conference = pldi,
  abstract = {When producing test inputs for a program, test generators ("fuzzers") can greatly profit from grammars that formally describe the language of expected inputs. In recent years, researchers thus have studied means to recover input grammars from programs and their executions. The GLADE algorithm by Bastani et al., published at PLDI 2017, was the first black-box approach to claim context-free approximation of input specification for non-trivial languages such as XML, Lisp, URLs, and more. Prompted by recent observations that the GLADE algorithm may show lower performance than reported in the original paper, we have reimplemented the GLADE algorithm from scratch. Our evaluation confirms that the effectiveness score (F1) reported in the GLADE paper is overly optimistic, and in some cases, based on the wrong language. Furthermore, GLADE fares poorly in several real-world languages evaluated, producing grammars that spend megabytes to enumerate inputs.}
}

@article{Bi2021,
  doi = {10.1016/j.jss.2021.111035},
  url = {https://doi.org/10.1016/j.jss.2021.111035},
  year = {2021},
  month = nov,
  publisher = {Elsevier},
  volume = {181},
  pages = {111035},
  author = {Tingting Bi and Wei Ding and Peng Liang and Antony Tang},
  title = {Architecture information communication in two {OSS} projects: The why, who, when, and what},
  journal = jss,
  abstract = {Architecture information is vital for Open Source Software (OSS) development, and mailing list is one of the widely used channels for developers to share and communicate architecture information. This work investigates the nature of architecture information communication (i.e., why, who, when, and what) by OSS developers via developer mailing lists. We employed a multiple case study approach to extract and analyze the architecture information communication from the developer mailing lists of two OSS projects, ArgoUML and Hibernate, during their development life-cycle of over 18 years. Our main findings are: (a) architecture negotiation and interpretation are the two main reasons (i.e., why) of architecture communication; (b) the amount of architecture information communicated in developer mailing lists decreases after the first stable release (i.e., when); (c) architecture communications centered around a few core developers (i.e., who); (d) and the most frequently communicated architecture elements (i.e., what) are Architecture Rationale and Architecture Model. There are a few similarities of architecture communication between the two OSS projects. Such similarities point to how OSS developers naturally gravitate towards the four aspects of architecture communication in OSS development.}
}

@article{Bijlsma2022,
  doi = {10.1002/spe.3061},
  title = {Evaluation of design pattern alternatives in Java},
  author = {Bijlsma, Lex A and Kok, Arjan J F and Passier, Harrie J M and Pootjes, Harold J and Stuurman, Sylvia},
  journal = {Softw. Pract. Exp.},
  publisher = {Wiley},
  volume = {52},
  number = {5},
  pages = {1305--1315},
  month = may,
  year = {2022},
  copyright = {http://creativecommons.org/licenses/by-nc-nd/4.0/},
  abstract = {Design patterns are standard solutions to common design problems. The famous Gang of Four book describes more than twenty design patterns for the object‐oriented paradigm. These patterns were developed more than twenty‐five years ago, using the programming language concepts available at that time. Patterns do not always fit underlying domain concepts. For example, even when a concrete strategy is a pure function, the classical strategy pattern represents this as a separate subclass and as such obscures the intent of this pattern with extra complexities due to the inheritance‐based implementation. Due to the ongoing development of oo‐languages, a relevant question is whether the implementation of these patterns can be improved using new language features, such that they fit more closely with the intent. An additional question is then how we can decide which implementation is to be preferred. In this article, we investigate both questions, using the strategy pattern as an example. Our main contribution is that we show how to reason about different implementations, using both the description of a design pattern and design principles as guidance.}
}

@misc{Biswas2022,
  author = {Sumon Biswas and Mohammad Wardat and Hridesh Rajan},
  title = {The Art and Practice of Data Science Pipelines: A Comprehensive Study of Data Science Pipelines In Theory, In-The-Small, and In-The-Large},
  year = {2022},
  eprint = {arXiv:2112.01590},
  howpublished = {ICSE 2022: The 44th International Conference on Software Engineering},
  doi = {10.1145/3510003.3510057},
}

@inproceedings{Bittner2022,
  doi = {10.1145/3540250.3549108},
  title = {Classifying edits to variability in source code},
  booktitle = esec-fse,
  author = {Bittner, Paul Maximilian and Tinnes, Christof and Schulthei{\ss}, Alexander and Viegener, S{\"o}ren and Kehrer, Timo and Th{\"u}m, Thomas},
  publisher = {ACM},
  month = nov,
  year = {2022},
  conference = esec-fse,
  abstract = {For highly configurable software systems, such as the Linux kernel, maintaining and evolving variability information along changes to source code poses a major challenge. While source code itself may be edited, also feature-to-code mappings may be introduced, removed, or changed. In practice, such edits are often conducted ad-hoc and without proper documentation. To support the maintenance and evolution of variability, it is desirable to understand the impact of each edit on the variability. We propose the first complete and unambiguous classification of edits to variability in source code by means of a catalog of edit classes. This catalog is based on a scheme that can be used to build classifications that are complete and unambiguous by construction. To this end, we introduce a complete and sound model for edits to variability. In about 21.5ms per commit, we validate the correctness and suitability of our classification by classifying each edit in 1.7 million commits in the change histories of 44 open-source software systems automatically. We are able to classify all edits with syntactically correct feature-to-code mappings and find that all our edit classes occur in practice.}
}

@misc{Blacher2022,
  author = {Mark Blacher and Joachim Giesen and Peter Sanders and Jan Wassenberg},
  title = {Vectorized and performance-portable Quicksort},
  year = {2022},
  eprint = {arXiv:2205.05982},
}

@article{Blackwell2019,
  doi = {10.1016/j.ijhcs.2019.06.009},
  url = {https://doi.org/10.1016/j.ijhcs.2019.06.009},
  year = {2019},
  month = nov,
  publisher = {Elsevier {BV}},
  volume = {131},
  pages = {52--63},
  author = {Alan F. Blackwell and Marian Petre and Luke Church},
  title = {Fifty years of the psychology of programming},
  journal = {International Journal of Human-Computer Studies},
  abstract = {Abstract This paper reflects on the evolution (past, present and future) of the 'psychology of programming' over the 50 year period of this anniversary issue. The International Journal of Human-Computer Studies (IJHCS) has been a key venue for much seminal work in this field, including its first foundations, and we review the changing research concerns seen in publications over these five decades. We relate this thematic evolution to research taking place over the same period within more specialist communities, especially the Psychology of Programming Interest Group (PPIG), the Empirical Studies of Programming series (ESP), and the ongoing community in Visual Languages and Human-Centric Computing (VL/HCC). Many other communities have interacted with psychology of programming, both influenced by research published within the specialist groups, and in turn influencing research priorities. We end with an overview of the core theories that have been developed over this period, as an introductory resource for new researchers, and also with the authors' own analysis of key priorities for future research.}
}

@inproceedings{Boag2022,
  doi = {10.1145/3531146.3533111},
  title = {Tech worker organizing for power and accountability},
  booktitle = {2022 {ACM} Conference on Fairness, Accountability, and Transparency},
  author = {Boag, William and Suresh, Harini and Lepe, Bianca and D'Ignazio, Catherine},
  publisher = {ACM},
  month = jun,
  year = {2022},
  conference = {FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency},
  abstract = {In recent years, there has been a growing interest in the field of “AI Ethics” and related areas. This field is purposefully broad, allowing for the intersection of numerous subfields and disciplines. However, a lot of work in this area thus far has centered computational methods, leading to a narrow lens where technical tools are framed as solutions for broader sociotechnical problems. In this work, we discuss a less-explored mode of what it can mean to “do” AI Ethics: tech worker collective action. Through collective action, the employees of powerful tech companies can act as a countervailing force against strong corporate impulses to grow or make a profit to the detriment of other values. In this work, we ground these efforts in existing scholarship of social movements and labor organizing. We characterize 150 documented collective actions, and explore several case studies of successful campaigns. Looking forward, we also identify under-explored types of actions, and provide conceptual frameworks and inspiration for how to utilize worker organizing as an effective lever for change.}
}

@misc{Bogner2022,
  author = {Justus Bogner and Manuel Merkel},
  title = {To Type or Not to Type? A Systematic Comparison of the Software Quality of JavaScript and TypeScript Applications on GitHub},
  year = {2022},
  eprint = {arXiv:2203.11115},
}

@misc{Borg2022,
  author = {Markus Borg and Leif Jonsson and Emelie Engström and Béla Bartalos and Attila Szabó},
  title = {Adopting Automated Bug Assignment in Practice: A Longitudinal Case Study at Ericsson},
  year = {2022},
  eprint = {arXiv:2209.08955},
}

@article{Britton2015,
  doi = {10.1080/02602938.2015.1116497},
  title = {Assessing teamwork in undergraduate education: a measurement tool to evaluate individual teamwork skills},
  author = {Britton, Emily and Simper, Natalie and Leger, Andrew and Stephenson, Jenn},
  journal = {Assess. Eval. High. Educ.},
  publisher = {Informa UK Limited},
  volume = {42},
  number = {3},
  pages = {378--397},
  month = apr,
  year = {2017},
  abstract = {Effective teamwork skills are essential for success in an increasingly team-based workplace. However, research suggests that there is often confusion concerning how teamwork is measured and assessed, making it difficult to develop these skills in undergraduate curricula. The goal of the present study was to develop a sustainable tool for assessing individual teamwork skills, with the intention of refining and measuring these skills over time. The TeamUp rubric was selected as the preliminary standardised measure of teamwork and tested in a second year undergraduate course (Phase One). Although the tool displayed acceptable psychometric properties, there was concern that it was too lengthy, compromising student completion. This prompted refinement and modification leading to the development of the Team-Q, which was again tested in the same undergraduate course (Phase Two). The new tool had high internal consistency, as well as conceptual similarity to other measures of teamwork. Estimates of inter-rater reliability were within a satisfactory range, although it was determined that logistical issues limited the feasibility of external evaluations. Preliminary evidence suggests that teamwork skills improve over time when taught and assessed, providing support for the continued application of the Team-Q as a tool for developing teamwork skills in undergraduate education.}
}

@inproceedings{Brodley2022,
  doi = {10.1145/3478431.3499352},
  title = {Broadening participation in computing via ubiquitous combined majors ({CS+X})},
  booktitle = sigcse,
  author = {Brodley, Carla E and Hescott, Benjamin J and Biron, Jessica and Ressing, Ali and Peiken, Melissa and Maravetz, Sarah and Mislove, Alan},
  publisher = {ACM},
  month = feb,
  year = {2022},
  conference = sigcse,
  abstract = {In 2001, Khoury College of Computer Sciences at Northeastern University created their first combined majors with Cognitive Psychology, Mathematics and Physics. This type of degree has often been referred to as \"CS+X\" in the literature and is increasingly relevant as the need for interdisciplinary computer scientists grows. As of 2021, students at Northeastern can choose among three computing majors (Computer Science, Data Science or Cybersecurity) and 42 combined majors, which combine one of the three computing degrees with one of 29 distinct majors in other fields. Prior to 2014, combined majors were with the sciences, business and design. Over the last seven years, we created 29 new combined majors, explicitly creating combinations with fields where there has traditionally been greater gender diversity. The resulting increase in student interest and gender diversity over the last seven years is compelling. As of Fall 2020, 44.6\% of the 2,800+ computing majors at Northeastern are pursuing combined majors, 39\% of whom are women. This is substantially higher than the 21.5\% reported in IPEDS for 2019 women computing graduates in the U.S. We did not observe any significant differences in racial and ethnic diversity between combined and computing only degrees. In this experience paper, we describe how we create and manage combined majors, and we present results on enrollments, admissions, graduation, internship placements, and how students discover combined majors.}
}

@inproceedings{Buffardi2020,
  doi = {10.1145/3328778.3366948},
  title = {Assessing individual contributions to software engineering projects with {Git} logs and user stories},
  booktitle = sigcse,
  author = {Buffardi, Kevin},
  publisher = {ACM},
  month = feb,
  year = {2020},
  conference = sigcse,
  abstract = {Software Engineering courses often incorporate large-scale projects with collaboration between students working in teams. However, it is difficult to objectively assess individual students when their projects are a product of collaborative efforts. This study explores measurements of individuals' contributions to their respective teams. I analyzed ten Software Engineering team projects (n=42) and evaluations of individual contributions using automated evaluation of the version control system history (Git logs) and user stories completed on their project management (Kanban) boards. Unique insights from meta-data within the Git history and Kanban board user stories reveal complicated relationships between these measurements and traditional assessments, such as peer review and subjective instructor evaluation. From the results, I suggest supplementing and validating traditional assessments with insights from individuals' commit history and user story contributions.}
}

@comment{CCC}

@article{CanovasIzquierdo2022,
  doi = {10.1007/s10664-021-10061-x},
  title = {On the analysis of non-coding roles in open source development},
  author = {{C{\'a}novas Izquierdo}, Javier Luis and Cabot, Jordi},
  abstract = {AbstractThe role of non-coding contributors in Open Source Software (OSS) is poorly understood. Most of current research around OSS development focuses on the coding aspects of the project (e.g., commits, pull requests or code reviews) while ignoring the potential of other types of contributions. Often, due to the assumption that these other contributions are not significant in number and that, in any case, they are handled by the same people that are also part of the ``coding team''. This paper aims to investigate whether this is actually the case by analyzing the frequency and diversity of non-coding contributions in OSS development. As a sample of projects for our study we have taken the 100 most popular projects in the ecosystem of NPM, a package manager for JavaScript. Our results validate the importance of dedicated non-coding contributors in OSS and the diversity of OSS communities as, typically, a contributor specializes in a specific subset of roles. We foresee that projects adopting explicit policies to attract and onboard them could see a positive impact in their long-term sustainability providing they also put in place the right governance strategies to facilitate the migration and collaboration among the different roles. As part of this work, we also provide a replicability package to facilitate further quantitative role-based analysis by other researchers.},
  journal = {Empir. Softw. Eng.},
  publisher = {Springer Science and Business Media LLC},
  volume = {27},
  number = {1},
  month = jan,
  year = {2022},
  copyright = {https://creativecommons.org/licenses/by/4.0}
}

@inproceedings{Chaparro2017,
  doi = {10.1145/3106237.3106285},
  url = {https://doi.org/10.1145/3106237.3106285},
  year = {2017},
  month = aug,
  publisher = {{ACM}},
  author = {Oscar Chaparro and Jing Lu and Fiorella Zampetti and Laura Moreno and Massimiliano Di Penta and Andrian Marcus and Gabriele Bavota and Vincent Ng},
  title = {Detecting missing information in bug descriptions},
  booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering}
}

@article{Chowdhury2022a,
  doi = {10.1109/tse.2021.3068901},
  url = {https://doi.org/10.1109/tse.2021.3068901},
  year = {2022},
  month = aug,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {48},
  number = {8},
  pages = {2695--2708},
  author = {Md Atique Reza Chowdhury and Rabe Abdalkareem and Emad Shihab and Bram Adams},
  title = {On the Untriviality of Trivial Packages: An Empirical Study of npm {JavaScript} Packages},
  journal = {{IEEE} Transactions on Software Engineering}
}

@misc{Chowdhury2022b,
  author = {Partha Das Chowdhury and Mohammad Tahaei and Awais Rashid},
  title = {Better Call Saltzer \& Schroeder: A Retrospective Security Analysis of SolarWinds \& Log4j},
  year = {2022},
  eprint = {arXiv:2211.02341},
}

@misc{Coleman2022,
  author = {Cora Coleman and William G. Griswold and Nick Mitchell},
  title = {Do Cloud Developers Prefer CLIs or Web Consoles? CLIs Mostly, Though It Varies by Task},
  year = {2022},
  eprint = {arXiv:2209.07365},
}

@article{Colicev2022,
  doi = {10.1002/smj.3443},
  url = {https://doi.org/10.1002/smj.3443},
  year = {2022},
  month = aug,
  publisher = {Wiley},
  author = {Anatoli Colicev and Tuuli Hakkarainen and Torben Pedersen},
  title = {Multi-project work and project performance: Friends or foes?},
  journal = {Strategic Management Journal}
}

@inproceedings{Collaris2022,
  doi = {10.1145/3546155.3546670},
  title = {Characterizing data scientists' mental models of local feature importance},
  booktitle = {Nordic {Human-Computer} Interaction Conference},
  author = {Collaris, Dennis and Weerts, Hilde J P and Miedema, Daphne and van Wijk, Jarke J and Pechenizkiy, Mykola},
  publisher = {ACM},
  month = oct,
  year = {2022},
  conference = {NordiCHI '22: Nordic Human-Computer Interaction Conference},
  abstract = {Feature importance is an approach that helps to explain machine learning model predictions. It works through assigning importance scores to input features of a particular model. Different techniques exist to derive these scores, with widely varying underlying assumptions of what importance means. Little research has been done to verify whether these assumptions match the expectations of the target user, which is imperative to ensure that feature importance values are not misinterpreted. In this work, we explore data scientists’ mental models of (local) feature importance and compare these with the conceptual models of the techniques. We first identify several properties of local feature importance techniques that could potentially lead to misinterpretations. Subsequently, we explore the expectations data scientists have about local feature importance through an exploratory (qualitative and quantitative) survey of 34 data scientists in industry. We compare the identified expectations to the theory and assumptions behind the techniques and find that the two are not (always) in agreement.}
}

@misc{Cosden2022,
  author = {Ian A. Cosden},
  title = {An RSE Group Model: Operational and Organizational Approaches From Princeton University's Central Research Software Engineering Group},
  year = {2022},
  eprint = {arXiv:2210.16261},
}

@comment{DDD}

@inproceedings{DalSasso2016,
  doi = {10.1109/QRS.2016.28},
  title = {What Makes a Satisficing Bug Report?},
  booktitle = {2016 {IEEE} International Conference on Software Quality, Reliability and Security ({QRS})},
  author = {{Dal Sasso}, Tommaso and Mocci, Andrea and Lanza, Michele},
  publisher = {IEEE},
  month = aug,
  year = {2016},
  conference = {2016 IEEE International Conference on Software Quality, Reliability and Security (QRS)},
  abstract = {To ensure quality of software systems, developers use bug reports to track defects. It is in the interest of users and developers that bug reports provide the necessary information to ease the fixing process. Past research found that users do not provide the information that developers deem ideally useful to fix a bug. This raises an interesting question: What is the satisficing information to speed up the bug fixing process? We conducted an observational study on the relation between provided report information and its lifetime, considering more than 650,000 reports from open-source systems using popular bug trackers. We distilled a meta-model for a minimal bug report, establishing a basic layer of core features. We found that few fields influence the resolution time and that customized fields have little impact on it. We performed a survey to investigate what users deem easy to provide in a bug report.}
}

@misc{DeAlmeida2022,
  author = {Eduardo Santana {de Almeida} and Iftekhar Ahmed and Andre {van der Hoek}},
  title = {Let's Go to the Whiteboard (Again):Perceptions from Software Architects on Whiteboard Architecture Meetings},
  year = {2022},
  eprint = {arXiv:2210.16089},
}

@inproceedings{Demirag2022,
  doi = {10.1145/3478431.3499378},
  url = {https://doi.org/10.1145/3478431.3499378},
  year = {2022},
  month = feb,
  publisher = {{ACM}},
  author = {Didem Demirag and Jeremy Clark},
  title = {Opening Sentences in Academic Writing},
  booktitle = {Proceedings of the 53rd {ACM} Technical Symposium on Computer Science Education}
}

@misc{DeSantana2022,
  author = {Taijara Loiola {de Santana} and Paulo Anselmo {da Mota Silveira Neto} and Eduardo Santana {de Almeida} and Iftekhar Ahmed},
  title = {Bug Analysis in Jupyter Notebook Projects: An Empirical Study},
  year = {2022},
  eprint = {arXiv:2210.06893},
}

@misc{DeSouzaSantos2022,
  author = {Ronnie E. de Souza Santos and Paul Ralph},
  title = {A Grounded Theory of Coordination in Remote-First and Hybrid Software Teams},
  year = {2022},
  eprint = {arXiv:2202.10445},
}

@inproceedings{Dias2021,
  doi = {10.1109/icse43902.2021.00093},
  url = {https://doi.org/10.1109/icse43902.2021.00093},
  year = {2021},
  month = may,
  publisher = {{IEEE}},
  author = {Edson Dias and Paulo Meirelles and Fernando Castor and Igor Steinmacher and Igor Wiese and Gustavo Pinto},
  title = {What Makes a Great Maintainer of Open Source Projects?},
  booktitle = icse,
  abstract = {Although Open Source Software (OSS) maintainers devote a significant proportion of their work to coding tasks, great maintainers must excel in many other activities beyond coding. Maintainers should care about fostering a community, helping new members to find their place, while also saying ``no'' to patches that although are well-coded and well-tested, do not contribute to the goal of the project. To perform all these activities masterfully, maintainers should exercise attributes that software engineers (working on closed source projects) do not always need to master. This paper aims to uncover, relate, and prioritize the unique attributes that great OSS maintainers might have. To achieve this goal, we conducted 33 semi-structured interviews with well-experienced maintainers that are the gatekeepers of notable projects such as the Linux Kernel, the Debian operating system, and the GitLab coding platform. After we analyzed the interviews and curated a list of attributes, we created a conceptual framework to explain how these attributes are connected. We then conducted a rating survey with 90 OSS contributors. We noted that ``technical excellence'' and ``communication'' are the most recurring attributes. When grouped, these attributes fit into four broad categories: management, social, technical, and personality. While we noted that ``sustain a long term vision of the project'' and being ``extremely careful'' seem to form the basis of our framework, we noted through our survey that the communication attribute was perceived as the most essential one.}
}

@inproceedings{Dickson2022,
  doi = {10.1145/3478431.3499320},
  url = {https://doi.org/10.1145/3478431.3499320},
  year = {2022},
  month = feb,
  publisher = {{ACM}},
  author = {Paul E. Dickson and Tim Richards and Brett A. Becker},
  title = {Experiences Implementing and Utilizing a Notional Machine in the Classroom},
  booktitle = {Proceedings of the 53rd {ACM} Technical Symposium on Computer Science Education}
}

@misc{Diercks2022,
  author = {Philipp Diercks and Dennis Gläser and Ontje Lünsdorf and Michael Selzer and Bernd Flemisch and Jörg F. Unger},
  title = {Evaluation of tools for describing, reproducing and reusing scientific workflows},
  year = {2022},
  eprint = {arXiv:2211.06429},
}

@inproceedings{DiGrazia2022,
  doi = {10.1145/3540250.3549114},
  title = {The evolution of type annotations in {Python}: an empirical study},
  booktitle = esec-fse,
  author = {{Di Grazia}, Luca and Pradel, Michael},
  publisher = {ACM},
  month = nov,
  year = {2022},
  conference = esec-fse,
  abstract = {Type annotations and gradual type checkers attempt to reveal errors and facilitate maintenance in dynamically typed programming languages. Despite the availability of these features and tools, it is currently unclear how quickly developers are adopting them, what strategies they follow when doing so, and whether adding type annotations reveals more type errors. This paper presents the first large-scale empirical study of the evolution of type annotations and type errors in Python. The study is based on an analysis of 1,414,936 type annotation changes, which we extract from 1,123,393 commits among 9,655 projects. Our results show that (i) type annotations are getting more popular, and once added, often remain unchanged in the projects for a long time, (ii) projects follow three evolution patterns for type annotation usage -- regular annotation, type sprints, and occasional uses -- and that the used pattern correlates with the number of contributors, (iii) more type annotations help find more type errors (0.704 correlation), but nevertheless, many commits (78.3\%) are committed despite having such errors. Our findings show that better developer training and automated techniques for adding type annotations are needed, as most code still remains unannotated, and they call for a better integration of gradual type checking into the development process.}
}

@article{Do2022,
  doi = {10.1109/tse.2020.3004525},
  url = {https://doi.org/10.1109/tse.2020.3004525},
  year = {2022},
  month = mar,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {48},
  number = {3},
  pages = {835--847},
  author = {Lisa Nguyen Quang Do and James R. Wright and Karim Ali},
  title = {Why Do Software Developers Use Static Analysis Tools? A User-Centered Study of Developer Needs and Motivations},
  journal = {{IEEE} Transactions on Software Engineering}
}

@article{Dogan2022,
  doi = {10.1016/j.infsof.2021.106737},
  title = {Towards a taxonomy of code review smells},
  author = {Do{\u{g}}an, Emre and T{\"u}z{\"u}n, Eray},
  journal = {Inf. Softw. Technol.},
  publisher = {Elsevier BV},
  volume = {142},
  number = {106737},
  pages = {106737},
  month = feb,
  year = {2022},
  abstract = {}
}

@article{Drage2022,
  doi = {10.1007/s13347-022-00543-1},
  title = {Does {AI} debias recruitment? Race, gender, and {AI's} ``eradication of difference''},
  author = {Drage, Eleanor and Mackereth, Kerry},
  abstract = {In this paper, we analyze two key claims offered by recruitment AI companies in relation to the development and deployment of AI-powered HR tools: (1) recruitment AI can objectively assess candidates by removing gender and race from their systems, and (2) this removal of gender and race will make recruitment fairer, help customers attain their DEI goals, and lay the foundations for a truly meritocratic culture to thrive within an organization. We argue that these claims are misleading for four reasons: First, attempts to ``strip'' gender and race from AI systems often misunderstand what gender and race are, casting them as isolatable attributes rather than broader systems of power. Second, the attempted outsourcing of ``diversity work'' to AI-powered hiring tools may unintentionally entrench cultures of problems within organizations. Third, AI hiring tools' supposedly neutral assessment of candidates' traits belie the power relationship between the observer and the observed. Specifically, the racialized history of character analysis and its associated processes of classification and categorization play into longer histories of taxonomical sorting and reflect the current demands and desires of the job market, even when not explicitly conducted along the lines of gender and race. Fourth, recruitment AI tools help produce the ``ideal candidate'' that they supposedly identify through by constructing associations between words and people's bodies. From these four conclusions outlined above, we offer three key recommendations to AI HR firms, their customers, and policy makers going forward.},
  journal = {Philos. Technol.},
  volume = {35},
  number = {4},
  pages = {89},
  month = oct,
  year = {2022},
  keywords = {Artificial intelligence; Bias; Gender; Hiring; Race; Recruitment}
}

@inproceedings{Dyer2022,
  doi = {10.1145/3540250.3549158},
  title = {An exploratory study on the predominant programming paradigms in {Python} code},
  booktitle = esec-fse,
  author = {Dyer, Robert and Chauhan, Jigyasa},
  publisher = {ACM},
  month = nov,
  year = {2022},
  conference = esec-fse,
  abstract = {Python is a multi-paradigm programming language that fully supports object-oriented (OO) programming. The language allows writing code in a non-procedural imperative manner, using procedures, using classes, or in a functional style. To date, no one has studied what paradigm(s), if any, are predominant in Python code and projects. In this work, we first define a technique to classify Python files into predominant paradigm(s). We then automate our approach and evaluate it against human judgements, showing over 80\% agreement. We then analyze over 100k open-source Python projects, automatically classifying each source file and investigating the paradigm distributions. The results indicate Python developers tend to heavily favor OO features. We also observed a positive correlation between OO and procedural paradigms and the size of the project. And despite few files or projects being predominantly functional, we still found many functional feature uses.}
}

@misc{Dykstra2022,
  author = {Josiah Dykstra and Kelly Shortridge and Jamie Met and Douglas Hough},
  title = {Sludge for Good: Slowing and Imposing Costs on Cyber Attackers},
  year = {2022},
  eprint = {arXiv:2211.16626},
}

@comment{EEE}

@misc{Etemadi2022,
  author = {Khashayar Etemadi and Aman Sharma and Fernanda Madeiral and Martin Monperrus},
  title = {Augmenting Diffs With Runtime Information},
  year = {2022},
  eprint = {arXiv:2212.11077},
}

@comment{FFF}

@article{Farzat2021,
  doi = {10.1109/tse.2019.2928293},
  url = {https://doi.org/10.1109/tse.2019.2928293},
  year = {2021},
  month = aug,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {8},
  pages = {1544--1558},
  author = {Fabio de A. Farzat and Marcio de O. Barros and Guilherme H. Travassos},
  title = {Evolving {JavaScript} Code to Reduce Load Time},
  journal = ieee-tse,
  abstract = {JavaScript is one of the most used programming languages for front-end development of Web applications. The increase in complexity of front-end features brings concerns about performance, especially the load and execution time of JavaScript code. In this paper, we propose an evolutionary program improvement technique to reduce the size of JavaScript programs and, therefore, the time required to load and execute them in Web applications. To guide the development of this technique, we performed an experimental study to characterize the patches applied to JavaScript programs to reduce their size while keeping the functionality required to pass all test cases in their test suites. We applied this technique to 19 JavaScript programs varying from 92 to 15,602 LOC and observed reductions from 0.2 to 73.8 percent of the original code, as well as a relationship between the quality of a program's test suite and the ability to reduce the size of its source code.}
}

@article{Feal2020,
  doi = {10.2478/popets-2020-0029},
  url = {https://doi.org/10.2478/popets-2020-0029},
  year = {2020},
  month = apr,
  publisher = {Walter de Gruyter {GmbH}},
  volume = {2020},
  number = {2},
  pages = {314--335},
  author = {\'{A}lvaro Feal and Paolo Calciati and Narseo Vallina-Rodriguez and Carmela Troncoso and Alessandra Gorla},
  title = {Angel or Devil? A Privacy Study of Mobile Parental Control Apps},
  journal = {Proceedings on Privacy Enhancing Technologies},
  abstract = {Android parental control applications are used by parents to monitor and limit their children's mobile behaviour (e.g., mobile apps usage, web browsing, calling, and texting). In order to offer this service, parental control apps require privileged access to sys-tem resources and access to sensitive data. This may significantly reduce the dangers associated with kids' online activities, but it raises important privacy con-cerns. These concerns have so far been overlooked by organizations providing recommendations regarding the use of parental control applications to the public. We conduct the first in-depth study of the Android parental control app's ecosystem from a privacy and regulatory point of view. We exhaustively study 46 apps from 43 developers which have a combined 20M installs in the Google Play Store. Using a combination of static and dynamic analysis we find that: these apps are on average more permissions-hungry than the top 150 apps in the Google Play Store, and tend to request more dangerous permissions with new releases; 11\% of the apps transmit personal data in the clear; 34\% of the apps gather and send personal information without appropriate consent; and 72\% of the apps share data with third parties (including online advertising and analytics services) without mentioning their presence in their privacy policies. In summary, parental control applications lack transparency and lack compliance with reg ulatory requirements. This holds even for those applications recommended by European and other national security centers.}
}

@inproceedings{Feng2022,
  doi = {10.1145/3510003.3510150},
  url = {https://doi.org/10.1145/3510003.3510150},
  year = {2022},
  month = may,
  publisher = {{ACM}},
  author = {Runhan Feng and Ziyang Yan and Shiyan Peng and Yuanyuan Zhang},
  title = {Automated detection of password leakage from public {GitHub} repositories},
  booktitle = {Proceedings of the 44th International Conference on Software Engineering}
}

@article{Ferreira2022,
  doi = {10.1002/spe.3044},
  url = {https://doi.org/10.1002/spe.3044},
  year = {2021},
  month = oct,
  publisher = {Wiley},
  volume = {52},
  number = {4},
  pages = {947--966},
  author = {Fabio Ferreira and Hudson Silva Borges and Marco Tulio Valente},
  title = {On the (un-)adoption of {JavaScript} front-end frameworks},
  journal = {Software: Practice and Experience},
  abstract = {JavaScript is characterized by a rich ecosystem of libraries and frameworks. A key element in this ecosystem are frameworks used for implementing the front-end of web-based applications, such as Vue and React. However, despite their relevance, we have few works investigating the factors that drive the adoption---and un-adoption---of front-end-based JavaScript frameworks. Therefore, in this article, we first report the results of a survey with 49 developers where we asked them to describe the factors they consider when selecting a front-end framework. In the second part of the work, we focus on projects that migrate from one framework to another since JavaScript's ecosystem is also very dynamic. Finally, we provide a quantitative characterization of the migration effort and reveal the main barriers faced by the developers during this effort. Although not completely generalizable, our central findings are as follows: (a) popularity and learnability are the key factors that motivate the choice of front-end frameworks in JavaScript; (b) from the 49 surveyed developers, one out of four have plans to migrate to another framework in the future; (c) the time spent performing the migration is greater than or equal to the time spent using the old framework in all studied projects. We conclude with a list of implications for practitioners, framework developers, tool builders, and researchers.}
}

@inproceedings{FinnieAnsley2022,
  doi = {10.1145/3511861.3511863},
  url = {https://doi.org/10.1145/3511861.3511863},
  year = {2022},
  month = feb,
  publisher = {{ACM}},
  author = {James Finnie-Ansley and Paul Denny and Brett A. Becker and Andrew Luxton-Reilly and James Prather},
  title = {The Robots Are Coming: Exploring the Implications of {OpenAI} Codex on Introductory Programming},
  booktitle = {Australasian Computing Education Conference}
}

@article{Flyvbjerg2022,
  doi = {10.1080/07421222.2022.2096544},
  title = {The empirical reality of {IT} project cost overruns: Discovering A power-law distribution},
  author = {Flyvbjerg, Bent and Budzier, Alexander and Lee, Jong Seok and Keil, Mark and Lunn, Daniel and Bester, Dirk W},
  journal = {J. Manag. Inf. Syst.},
  publisher = {Informa UK Limited},
  volume = {39},
  number = {3},
  pages = {607--639},
  month = jul,
  year = {2022},
  abstract = {ABSTRACT If managers assume a normal or near-normal distribution of Information Technology (IT) project cost overruns, as is common, and cost overruns can be shown to follow a power-law distribution, managers may be unwittingly exposing their organizations to extreme risk by severely underestimating the probability of large cost overruns. In this research, we collect and analyze a large sample comprised of 5,392 IT projects to empirically examine the probability distribution of IT project cost overruns. Further, we propose and examine a mechanism that can explain such a distribution. Our results reveal that IT projects are far riskier in terms of cost than normally assumed by decision makers and scholars. Specifically, we found that IT project cost overruns follow a power-law distribution in which there are a large number of projects with relatively small overruns and a fat tail that includes a smaller number of projects with extreme overruns. A possible generative mechanism for the identified power-law distribution is found in interdependencies among technological components in IT systems. We propose and demonstrate, through computer simulation, that a problem in a single technological component can lead to chain reactions in which other interdependent components are affected, causing substantial overruns. What the power law tells us is that extreme IT project cost overruns will occur and that the prevalence of these will be grossly underestimated if managers assume that overruns follow a normal or near-normal distribution. This underscores the importance of realistically assessing and mitigating the cost risk of new IT projects up front.}
}

@inproceedings{Foidl2022,
  doi = {10.1145/3522664.3528590},
  title = {Data smells},
  booktitle = {Proceedings of the 1st International Conference on {AI} Engineering: Software Engineering for {AI}},
  author = {Foidl, Harald and Felderer, Michael and Ramler, Rudolf},
  publisher = {ACM},
  month = may,
  year = {2022},
  conference = {CAIN '22: 1st Conference on AI Engineering - Software Engineering for AI},
  abstract = {High data quality is fundamental for today’s AI-based systems. However, although data quality has been an object of research for decades, there is a clear lack of research on potential data quality issues (e.g., ambiguous, extraneous values). These kinds of issues are latent in nature and thus often not obvious. Nevertheless, they can be associated with an increased risk of future problems in AI-based systems (e.g., technical debt, data-induced faults). As a counterpart to code smells in software engineering, we refer to such issues as Data Smells. This article conceptualizes data smells and elaborates on their causes, consequences, detection, and use in the context of AI-based systems. In addition, a catalogue of 36 data smells divided into three categories (i.e., Believability Smells, Understandability Smells, Consistency Smells) is presented. Moreover, the article outlines tool support for detecting data smells and presents the result of an initial smell detection on more than 240 real-world datasets.}
}

@article{Fregnan2023,
  doi = {10.1016/j.jss.2022.111506},
  url = {https://doi.org/10.1016/j.jss.2022.111506},
  year = {2023},
  month = jan,
  publisher = {Elsevier {BV}},
  volume = {195},
  pages = {111506},
  author = {Enrico Fregnan and Josua Fr\"{o}hlich and Davide Spadini and Alberto Bacchelli},
  title = {Graph-based visualization of merge requests for code review},
  journal = {Journal of Systems and Software}
}

@inproceedings{Friend2022,
  doi = {10.1145/3564721.3564738},
  title = {Solve this! {K-12} {CS} education teachers' problems of practice},
  booktitle = {Koli Calling '22: 22nd Koli Calling International Conference on Computing Education Research},
  author = {Friend, Michelle and Mcgill, Monica and Reinking, Anni},
  publisher = {ACM},
  month = nov,
  year = {2022},
  conference = {Koli 2022: 22nd Koli Calling International Conference on Computing Education Research},
  abstract = {Problem. Educational research identifies answerable questions, but often does not address the problems K-12 teachers identify as important. Further, academic research findings can be difficult for teachers to apply to their practices and unique contexts. Currently, little research exists on the lived experiences of primary and secondary instructors who teach computer science (CS) or computational thinking (CT) and also on the specific problems of practice teachers face when teaching CS. Research Question. What problems of practice do K-12 teachers face when teaching CS/CT? Method. Data for this qualitative study was collected using an online questionnaire distributed to teachers internationally. CS/CT teachers responded to an open-ended prompt asking for problems related to teaching CS. The data was analyzed using descriptive first-round coding and focused second-round coding. Validity was established through collaborative coding. Analysis was theorized using locus of control. Findings. Problems with students encompassed behavioral, cognitive, and attitudinal issues, as well as lack of home support or resources. Teachers identified many problems of policy notably stemming from lack of resources or support from administrators. A smaller number of challenges, such as lack of content knowledge, were situated within teachers themselves. While some problems such as student motivation are general, a number of responses identified unique challenges in CS education compared to other disciplines. Implications. Identifying problems faced by teachers can guide professional development offerings, help researchers develop studies that would result in meaningful improvement to CS education, and suggest policy decisions which would result in better outcomes for students.}
}

@comment{GGG}

@article{Gaffney2022,
  doi = {10.14778/3554821.3554842},
  title = {{SQLite}},
  author = {Gaffney, Kevin P and Prammer, Martin and Brasfield, Larry and Hipp, D Richard and Kennedy, Dan and Patel, Jignesh M},
  abstract = {In the two decades following its initial release, SQLite has become the most widely deployed database engine in existence. Today, SQLite is found in nearly every smartphone, computer, web browser, television, and automobile. Several factors are likely responsible for its ubiquity, including its in-process design, standalone codebase, extensive test suite, and cross-platform file format. While it supports complex analytical queries, SQLite is primarily designed for fast online transaction processing (OLTP), employing row-oriented execution and a B-tree storage format. However, fueled by the rise of edge computing and data science, there is a growing need for efficient in-process online analytical processing (OLAP). DuckDB, a database engine nicknamed ``the SQLite for analytics'', has recently emerged to meet this demand. While DuckDB has shown strong performance on OLAP benchmarks, it is unclear how SQLite compares. Furthermore, we are aware of no work that attempts to identify root causes for SQLite's performance behavior on OLAP workloads. In this paper, we discuss SQLite in the context of this changing workload landscape. We describe how SQLite evolved from its humble beginnings to the full-featured database engine it is today. We evaluate the performance of modern SQLite on three benchmarks, each representing a different flavor of in-process data management, including transactional, analytical, and blob processing. We delve into analytical data processing on SQLite, identifying key bottlenecks and weighing potential solutions. As a result of our optimizations, SQLite is now up to 4.2X faster on SSB. Finally, we discuss the future of SQLite, envisioning how it will evolve to meet new demands and challenges.},
  journal = {Proceedings VLDB Endowment},
  publisher = {Association for Computing Machinery (ACM)},
  volume = {15},
  number = {12},
  pages = {3535--3547},
  month = aug,
  year = {2022}
}

@inproceedings{Galappaththi2022,
  doi = {10.1145/3524842.3528435},
  title = {Does this apply to me?},
  booktitle = msr,
  author = {Galappaththi, Akalanka and Nadi, Sarah and Treude, Christoph},
  publisher = {ACM},
  month = may,
  year = {2022},
  abstract = {Stack Overflow has become an essential technical resource for developers. However, given the vast amount of knowledge available on Stack Overflow, finding the right information that is relevant for a given task is still challenging, especially when a developer is looking for a solution that applies to their specific requirements or technology stack. Clearly marking answers with their technical context, i.e., the information that characterizes the technologies and assumptions needed for this answer, is potentially one way to improve navigation. However, there is no information about how often such context is mentioned, and what kind of information it might offer. In this paper, we conduct an empirical study to understand the occurrence of technical context in Stack Overflow answers and comments, using tags as a proxy for technical context. We specifically focus on additional context, where answers/comments mention information that is not already discussed in the question. Our results show that nearly half of our studied threads contain at least one additional context. We find that almost 50\% of the additional context are either a library/framework, a programming language, a tool/application, an API, or a database. Overall, our findings show the promise of using additional context as navigational cues.}
}

@misc{Gamblin2022,
  author = {Todd Gamblin and Massimiliano Culpo and Gregory Becker and Sergei Shudler},
  title = {Using Answer Set Programming for HPC Dependency Solving},
  year = {2022},
  eprint = {arXiv:2210.08404},
}

@inproceedings{Georgiou2022,
  doi = {10.1145/3510003.3510221},
  url = {https://doi.org/10.1145/3510003.3510221},
  year = {2022},
  month = may,
  publisher = {{ACM}},
  author = {Stefanos Georgiou and Maria Kechagia and Tushar Sharma and Federica Sarro and Ying Zou},
  title = {Green {AI}},
  booktitle = {Proceedings of the 44th International Conference on Software Engineering}
}

@inproceedings{Getseva2022,
  doi = {10.1145/3502718.3524794},
  title = {An empirical analysis of code-tracing concepts},
  booktitle = iticse,
  author = {Getseva, Vanesa and Kumar, Amruth N},
  publisher = {ACM},
  month = jul,
  year = {2022},
  conference = iticse,
  abstract = {Which code-tracing concepts are introductory programming students likely to learn from classroom instruction and which ones need additional problem-solving practice to master? Are there relationships among programming concepts that can be used to build adaptive assessment instruments? To answer these questions, we analyzed the data collected over several semesters by a suite of code-tracing tutors called problets, that administered pre-test, practice, post-test protocol. Each tutor covered a single programming topic, which consisted of 9-25 concepts. For each concept, we used the pretest data to calculate the probability that students knew the concept before using the tutor. Using a weighted average of the concept probabilities, we found that students had learned some topics more than others: if/if-else (0.85), function behavior (0.76), arrays (0.73), while (0.7), for (0.69), switch (0.67), and debugging functions (0.55). Some of the concepts on which students needed additional practice included bugs, nested loops and back-to-back loops. Expressions, even when used in novel contexts, were not challenging for students. We built a Bayesian network for each topic based on conditional probabilities to discover the concepts that must be covered, and those whose coverage is redundant in the presence of other concepts. A strength of this empirical study is that it uses a large dataset collected from multiple institutions over multiple semesters. We also list threats to the validity of the study.}
}

@misc{Gorz2022,
  author = {Philipp G\"{o}rz and Björn Mathis and Keno Hassler and Emre Güler and Thorsten Holz and Andreas Zeller and Rahul Gopinath},
  title = {How to Compare Fuzzers},
  year = {2022},
  eprint = {arXiv:2212.03075},
}

@misc{Gote2022,
  author = {Christoph Gote and Pavlin Mavrodiev and Frank Schweitzer and Ingo Scholtes},
  title = {Big Data = Big Insights? Operationalising Brooks' Law in a Massive GitHub Data Set},
  year = {2022},
  eprint = {arXiv:2201.04588},
}

@article{Graziotin2022,
  doi = {10.1145/3469888},
  title = {Psychometrics in behavioral software engineering: A methodological introduction with guidelines},
  author = {Graziotin, Daniel and Lenberg, Per and Feldt, Robert and Wagner, Stefan},
  abstract = {A meaningful and deep understanding of the human aspects of software engineering (SE) requires psychological constructs to be considered. Psychology theory can facilitate the systematic and sound development as well as the adoption of instruments (e.g., psychological tests, questionnaires) to assess these constructs. In particular, to ensure high quality, the psychometric properties of instruments need evaluation. In this article, we provide an introduction to psychometric theory for the evaluation of measurement instruments for SE researchers. We present guidelines that enable using existing instruments and developing new ones adequately. We conducted a comprehensive review of the psychology literature framed by the Standards for Educational and Psychological Testing. We detail activities used when operationalizing new psychological constructs, such as item pooling, item review, pilot testing, item analysis, factor analysis, statistical property of items, reliability, validity, and fairness in testing and test bias. We provide an openly available example of a psychometric evaluation based on our guideline. We hope to encourage a culture change in SE research towards the adoption of established methods from psychology. To improve the quality of behavioral research in SE, studies focusing on introducing, validating, and then using psychometric instruments need to be more common.},
  journal = {ACM Trans. Softw. Eng. Methodol.},
  publisher = {Association for Computing Machinery (ACM)},
  volume = {31},
  number = {1},
  pages = {1--36},
  month = jan,
  year = {2022}
}

@misc{Grotov2022,
  author = {Konstantin Grotov and Sergey Titov and Vladimir Sotnikov and Yaroslav Golubev and Timofey Bryksin},
  title = {A Large-Scale Comparison of Python Code in Jupyter Notebooks and Scripts},
  year = {2022},
  eprint = {arXiv:2203.16718},
}

@misc{Guizani2022a,
  author = {Mariam Guizani and Thomas Zimmermann and Anita Sarma and Denae Ford},
  title = {Attracting and Retaining OSS Contributors with a Maintainer Dashboard},
  year = {2022},
  eprint = {arXiv:2202.07740},
}

@misc{Guizani2022b,
  author = {Mariam Guizani and Igor Steinmacher and Jillian Emard and Abrar Fallatah and Margaret Burnett and Anita Sarma},
  title = {How to Debug Inclusivity Bugs? A Debugging Process with Information Architecture},
  year = {2022},
  eprint = {arXiv:2202.13303},
  doi = {10.1145/3510458.3513009},
}

@comment{HHH}

@article{Haduong2019,
  doi = {10.1108/ILS-05-2018-0037},
  title = {``I like computers. {I} hate coding'': a portrait of two teens' experiences},
  author = {Haduong, Paulina},
  journal = {Inf. Learn. Sci.},
  publisher = {Emerald},
  volume = {120},
  number = {{5}/6},
  pages = {349--365},
  month = may,
  year = {2019},
  abstract = {Purpose Some empirical evidence suggests that historically marginalized young people may enter introductory programming experiences with skepticism or reluctance, because of negative perceptions of the computing field. This paper aims to explore how learner identity and motivation can affect their experiences in an introductory computer science (CS) experience, particularly for young people who have some prior experience with computing. In this program, learners were asked to develop digital media artifacts about civic issues using Scratch, a block-based programming language.   Design/methodology/approach Through participant observation as a teacher and designer of the course, artifact analysis of student-generated computer programs and design journals, as well as with two follow-up 1-h interviews, the author used the qualitative method of portraiture to examine how two reluctant learners experienced a six-week introductory CS program.   Findings These learners’ experiences illuminate the ways in which identity, community and competence can play a role in supporting learner motivation in CS education experiences.   Research limitations/implications As more students have multiple introductory computing encounters, educators need to take into account not only their perceptions of the computing field more broadly but also specific prior encounters with programming. Because of the chosen research approach, the research results may lack generalizability. Researchers are encouraged to explore other contexts and examples further.   Practical implications This portrait highlights the need for researchers and educators to take into account student motivation in the design of learning environments.   Originality/value This portrait offers a novel examination of novice programmer experiences through the choice in method, as well as new examples of how learner identity can affect student motivation.}
}

@inproceedings{Hartel2022,
  doi = {10.1145/3524842.3527960},
  title = {Operationalizing threats to {MSR} studies by simulation-based testing},
  booktitle = msr,
  author = {H{\"a}rtel, Johannes and L{\"a}mmel, Ralf},
  publisher = {ACM},
  month = may,
  year = {2022},
  abstract = {Quantitative studies on the border between Mining Software Repository (MSR) and Empirical Software Engineering (ESE) apply data analysis methods, like regression modeling, statistic tests or correlation analysis, to commits or pulls to better understand the software development process. Such studies assure the validity of the reported results by following a sound methodology. However, with increasing complexity, parts of the methodology can still go wrong. This may result in MSR/ESE studies with undetected threats to validity. In this paper, we propose to systematically protect against threats by operationalizing their treatment using simulations. A simulation substitutes observed and unobserved data, related to an MSR/ESE scenario, with synthetic data, carefully defined according to plausible assumptions on the scenario. Within a simulation, unobserved data becomes transparent, which is the key difference to a real study, necessary to detect threats to an analysis methodology. Running an analysis methodology on synthetic data may detect basic technical bugs and misinterpretations, but it also improves the trust in the methodology. The contribution of a simulation is to operationalize testing the impact of important assumptions. Assumptions still need to be rated for plausibility. We evaluate simulation-based testing by operationalizing undetected threats in the context of four published MSR/ESE studies. We recommend that future research uses such more systematic treatment of threats, as a contribution against the reproducibility crisis.}
}

@inproceedings{Head2020,
  doi = {10.1145/3313831.3376798},
  title = {Composing flexibly-organized step-by-step tutorials from linked source code, snippets, and outputs},
  booktitle = {Proceedings of the 2020 {CHI} Conference on Human Factors in Computing Systems},
  author = {Head, Andrew and Jiang, Jason and Smith, James and Hearst, Marti A and Hartmann, Bj{\"o}rn},
  publisher = {ACM},
  month = apr,
  year = {2020},
  conference = {CHI '20: CHI Conference on Human Factors in Computing Systems},
  abstract = {Programming tutorials are a pervasive, versatile medium for teaching programming. In this paper, we report on the content and structure of programming tutorials, the pain points authors experience in writing them, and a design for a tool to help improve this process. An interview study with 12 experienced tutorial authors found that they construct documents by interleaving code snippets with text and illustrative outputs. It also revealed that authors must often keep related artifacts of source programs, snippets, and outputs consistent as a program evolves. A content analysis of 200 frequently-referenced tutorials on the web also found that most tutorials contain related artifacts---duplicate code and outputs generated from snippets---that an author would need to keep consistent with each other. To address these needs, we designed a tool called Torii with novel authoring capabilities. An in-lab study showed that tutorial authors can successfully use the tool for the unique affordances identified, and provides guidance for designing future tools for tutorial authoring.}
}

@inproceedings{Hellman2022,
  doi = {10.1145/3528579.3529178},
  title = {Characterizing user behaviors in open-source software user forums},
  booktitle = {Proceedings of the 15th International Conference on Cooperative and Human Aspects of Software Engineering},
  author = {Hellman, Jazlyn and Chen, Jiahao and Uddin, Md Sami and Cheng, Jinghui and Guo, Jin L C},
  publisher = {ACM},
  month = may,
  year = {2022},
  conference = icse,
  abstract = {User forums of Open Source Software (OSS) enable end-users to collaboratively discuss problems concerning the OSS applications. Despite decades of research on OSS, we know very little about how end-users engage with OSS communities on these forums, in particular, the challenges that hinder their continuous and meaningful participation in the OSS community. Many previous works are developer-centric and overlook the importance of end-user forums. As a result, end-users' expectations are seldom reflected in OSS development. To better understand user behaviors in OSS user forums, we carried out an empirical study analyzing about 1.3 million posts from user forums of four popular OSS applications: Zotero, Audacity, VLC, and RStudio. Through analyzing the contribution patterns of three common user types (end-users, developers, and organizers), we observed that end-users not only initiated most of the threads (above 96\% of threads in three projects, 86\% in the other), but also acted as the significant contributors for responding to other users' posts, even though they tended to lack confidence in their activities as indicated by psycho-linguistic analyses. Moreover, we found end-users more open, reflecting a more positive emotion in communication than organizers and developers in the forums. Our work contributes new knowledge about end-users' activities and behaviors in OSS user forums that the vital OSS stakeholders can leverage to improve end-user engagement in the OSS development process.}
}

@misc{Hidellaarachchi2022,
  author = {Dulaji Hidellaarachchi and John Grundy and Rashina Hoda and Ingo Mueller},
  title = {Does personality impact requirements engineering Activities?},
  year = {2022},
  eprint = {arXiv:2210.07807},
}

@article{Hoda2021,
  doi = {10.1109/tse.2021.3106280},
  url = {https://doi.org/10.1109/tse.2021.3106280},
  year = {2021},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  pages = {1--1},
  author = {Rashina Hoda},
  title = {Socio-Technical Grounded Theory for Software Engineering},
  journal = ieee-tse,
  abstract = {Grounded Theory (GT), a sociological research method designed to study social phenomena, is increasingly being used to investigate the human and social aspects of software engineering (SE). However, being written by and for sociologists, GT is often challenging for a majority of SE researchers to understand and apply. Additionally, SE researchers attempting ad hoc adaptations of traditional GT guidelines for modern socio-technical (ST) contexts often struggle in the absence of clear and relevant guidelines to do so, resulting in poor quality studies. To overcome these research community challenges and leverage modern research opportunities, this paper presents Socio-Technical Grounded Theory (STGT) designed to ease application and achieve quality outcomes. It defines what exactly is meant by an ST research context and presents the STGT guidelines that expand GT's philosophical foundations, provide increased clarity and flexibility in its methodological steps and procedures, define possible scope and contexts of application, encourage frequent reporting of a variety of interim, preliminary, and mature outcomes, and introduce nuanced evaluation guidelines for different outcomes. It is hoped that the SE research community and related ST disciplines such as computer science, data science, artificial intelligence, information systems, human computer/robot/AI interaction, human-centered emerging technologies (and increasingly other disciplines being transformed by rapid digitalisation and AI-based augmentation), will benefit from applying STGT to conduct quality research studies and systematically produce rich findings and mature theories with confidence.}
}

@article{Hundhausen2022,
  doi = {10.1080/08993408.2022.2071543},
  title = {Assessing individual contributions to software engineering projects: a replication study},
  author = {Hundhausen, C D and Conrad, P T and Carter, A S and Adesope, O},
  journal = {Comput. Sci. Educ.},
  publisher = {Informa UK Limited},
  volume = {32},
  number = {3},
  pages = {335--354},
  month = jul,
  year = {2022},
  abstract = {ABSTRACT Background and Context Assessing team members’ indivdiual contributions to software development projects poses a key problem for computing instructors. While instructors typically rely on subjective assessments, objective assessments could provide a more robust picture. To explore this possibility, In a 2020 paper, Buffardi presented a correlational analysis of objective metrics and subjective metrics in an advanced software engineering project course (n= 41 students and 10 teams), finding only two significant correlations. Objective To explore the robustness of Buffardi’s findings and gain further insight, we conducted a larger scale replication of the Buffardi study (n = 118 students and 25 teams) in three courses at three institutions. Method We collected the same data as in the Buffardi study and computed the same measures from those data. We replicated Buffardi’s exploratory, correlational and regression analyses of objective and subjective measures. Findings While replicating four of Buffardi’s five significant correlational findings and partially replicating the findings of Buffardi’s regression analyses, our results go beyond those of Buffardi by identifying eight additional significant correlations. Implications In contrast to Buffardi’s study, our larger scale study suggests that subjective and objective measures of individual performance in team software development projects can be fruitfully combined to provide consistent and complementary assessments of individual performance.}
}

@article{Huszar2022,
  doi = {10.1073/pnas.2025334119},
  title = {Algorithmic amplification of politics on Twitter},
  author = {Husz{\'a}r, Ferenc and Ktena, Sofia Ira and O'Brien, Conor and Belli, Luca and Schlaikjer, Andrew and Hardt, Moritz},
  journal = {Proc. Natl. Acad. Sci. U. S. A.},
  publisher = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {1},
  pages = {e2025334119},
  month = jan,
  year = {2022},
  keywords = {algorithmic personalization; media amplification; political bias; social media},
  copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
  abstract = {Significance The role of social media in political discourse has been the topic of intense scholarly and public debate. Politicians and commentators from all sides allege that Twitter’s algorithms amplify their opponents’ voices, or silence theirs. Policy makers and researchers have thus called for increased transparency on how algorithms influence exposure to political content on the platform. Based on a massive-scale experiment involving millions of Twitter users, a fine-grained analysis of political parties in seven countries, and 6.2 million news articles shared in the United States, this study carries out the most comprehensive audit of an algorithmic recommender system and its effects on political content. Results unveil that the political right enjoys higher amplification compared to the political left. Content on Twitter’s home timeline is selected and ordered by personalization algorithms. By consistently ranking certain content higher, these algorithms may amplify some messages while reducing the visibility of others. There’s been intense public and scholarly debate about the possibility that some political groups benefit more from algorithmic amplification than others. We provide quantitative evidence from a long-running, massive-scale randomized experiment on the Twitter platform that committed a randomized control group including nearly 2 million daily active accounts to a reverse-chronological content feed free of algorithmic personalization. We present two sets of findings. First, we studied tweets by elected legislators from major political parties in seven countries. Our results reveal a remarkably consistent trend: In six out of seven countries studied, the mainstream political right enjoys higher algorithmic amplification than the mainstream political left. Consistent with this overall trend, our second set of findings studying the US media landscape revealed that algorithmic amplification favors right-leaning news sources. We further looked at whether algorithms amplify far-left and far-right political groups more than moderate ones; contrary to prevailing public belief, we did not find evidence to support this hypothesis. We hope our findings will contribute to an evidence-based debate on the role personalization algorithms play in shaping political content consumption.}
}

@comment{III}

@article{Idowu2022,
  doi = {10.1145/3543847},
  title = {Asset management in machine learning: State-of-research and state-of-practice},
  author = {Idowu, Samuel and Str{\"u}ber, Daniel and Berger, Thorsten},
  journal = {ACM Comput. Surv.},
  publisher = {Association for Computing Machinery (ACM)},
  month = jun,
  year = {2022},
  abstract = {Machine learning components are essential for today’s software systems, causing a need to adapt traditional software engineering practices when developing machine-learning-based systems. This need is pronounced due to many development-related challenges of machine learning components such as asset, experiment, and dependency management. Recently, many asset management tools addressing these challenges have become available. It is essential to understand the support such tools offer to facilitate research and practice on building new management tools with native supports for machine learning and software engineering assets. This article positions machine learning asset management as a discipline that provides improved methods and tools for performing operations on machine learning assets. We present a feature-based survey of 18 state-of-practice and 12 state-of-research tools supporting machine-learning asset management. We overview their features for managing the types of assets used in machine learning experiments. Most state-of-research tools focus on tracking, exploring, and retrieving assets to address development concerns such as reproducibility, while the state-of-practice tools also offer collaboration and workflow-execution-related operations. In addition, assets are primarily tracked intrusively from the source code through APIs and managed via web dashboards or command-line interfaces. We identify asynchronous collaboration and asset reusability as directions for new tools and techniques.}
}

@inproceedings{Imam2021,
  doi = {10.1109/msr52588.2021.00085},
  url = {https://doi.org/10.1109/msr52588.2021.00085},
  year = {2021},
  month = may,
  publisher = {{IEEE}},
  author = {Ahmed Imam and Tapajit Dey},
  title = {Tracking Hackathon Code Creation and Reuse},
  booktitle = msr,
  abstract = {Background: Hackathons have become popular events for teams to collaborate on projects and develop software prototypes. Most existing research focuses on activities during an event with limited attention to the evolution of the code brought to or created during a hackathon. Aim: We aim to understand the evolution of hackathon-related code, specifically, how much hackathon teams rely on pre-existing code or how much new code they develop during a hackathon. Moreover, we aim to understand if and where that code gets reused. Method: We collected information about 22,183 hackathon projects from Devpost---a hackathon database---and obtained related code (blobs), authors, and project characteristics from the World of Code. We investigated if code blobs in hackathon projects were created before, during, or after an event by identifying the original blob creation date and author, and also checked if the original author was a hackathon project member. We tracked code reuse by first identifying all commits containing blobs created during an event before determining all projects that contain those commits. Result: While only approximately 9.14\% of the code blobs are created during hackathons, this amount is still significant considering time and member constraints of such events. Approximately a third of these code blobs get reused in other projects. Conclusion: Our study demonstrates to what extent pre-existing code is used and new code is created during a hackathon and how much of it is reused elsewhere afterwards. Our findings help to better understand code reuse as a phenomenon and the role of hackathons in this context and can serve as a starting point for further studies in this area.}
}

@comment{JJJ}

@inproceedings{Jeffries2022,
  doi = {10.1145/3502718.3524809},
  title = {115 ways not to say hello, world!},
  booktitle = iticse,
  author = {Jeffries, Bryn and Lee, Jung A and Koprinska, Irena},
  publisher = {ACM},
  month = jul,
  year = {2022},
  conference = iticse,
  abstract = {Online programming courses can provide detailed automatic feedback for code that fails to meet various test conditions, but novice students often struggle with syntax errors and are unable to write valid testable code. Even for very simple exercises, the range of incorrect code can be surprising to educators with mastery of a programming language. This research paper presents an analysis of the error messages from code run by students in an introductory Python~3 programming course, participated in by 8680 primary and high-school students from 680 institutions. The invalid programs demonstrate a wide diversity of mistakes: even for a one-line \"Hello World!'' exercise there were 115 unique invalid programs. The most common errors are identified and compared to the topics introduced in the course. The most generic errors in selected exercises are investigated in greater detail to understand the underlying causes. While the majority of students attempting an exercise reach a successful outcome, many students encounter at least one error in their code. Of these, many such errors indicate basic mistakes, such as unquoted string literals, even in exercises late in the course for which some proficiency of earlier concepts is assumed. These observations suggest there is significant scope to provide greater reinforcement of students' understanding of earlier concepts.}
}

@article{Joblin2022,
  doi = {10.1145/3504003},
  title = {How do successful and failed projects differ? A Socio-technical analysis},
  author = {Joblin, Mitchell and Apel, Sven},
  abstract = {Software development is at the intersection of the social realm , involving people who develop the software, and the technical realm , involving artifacts (code, docs, etc.) that are being produced. It has been shown that a socio-technical perspective provides rich information about the state of a software project. In particular, we are interested in socio-technical factors that are associated with project success . For this purpose, we frame the task as a network classification problem. We show how a set of heterogeneous networks composed of social and technical entities can be jointly embedded in a single vector space enabling mathematically sound comparisons between distinct software projects. Our approach is specifically designed using intuitive metrics stemming from network analysis and statistics to ease the interpretation of results in the context of software engineering wisdom. Based on a selection of 32 open-source projects, we perform an empirical study to validate our approach considering three prediction scenarios to test the classification model's ability generalizing to: (1) randomly held-out project snapshots, (2) future project states, and (3) entirely new projects. Our results provide evidence that a socio-technical perspective is superior to a pure social or technical perspective when it comes to early indicators of future project success. To our surprise, the methodology proposed here even shows evidence of being able to generalize to entirely novel (project hold-out set) software projects reaching predication accuracies of 80\%, which is a further testament to the efficacy of our approach and beyond what has been possible so far. In addition, we identify key features that are strongly associated with project success. Our results indicate that even relatively simple socio-technical networks capture highly relevant and interpretable information about the early indicators of future project success.},
  journal = {ACM Trans. Softw. Eng. Methodol.},
  publisher = {Association for Computing Machinery (ACM)},
  month = feb,
  year = {2022}
}

@inproceedings{Johnson2016,
  doi = {10.1109/cseet.2016.29},
  url = {https://doi.org/10.1109/cseet.2016.29},
  year = {2016},
  month = apr,
  publisher = {{IEEE}},
  author = {Philip Johnson and Dan Port and Emily Hill},
  title = {An Athletic Approach to Software Engineering Education},
  booktitle = {2016 {IEEE} 29th International Conference on Software Engineering Education and Training ({CSEET})},
  abstract = {We present our findings after two years of experience involving three instructors using an "athletic" approach to software engineering education (AthSE). Co-author Johnson developed AthSE in 2013 to address issues he experienced teaching graduate and undergraduate software engineering. Co-authors Port and Hill subsequently adapted the original approach to their own software courses. AthSE is a pedagogy in which the course is organized into a series of skills to be mastered. For each skill, students are given practice "Workouts" along with videos showing the instructor performing the Workout both correctly and quickly. Unlike traditional home-work assignments, students are advised to repeat the Workout not only until they can complete it correctly, but also as quickly as the instructor. In this experience report we investigate the following question: how can software engineering education be redesigned as an athletic endeavor, and will this provide more efficient and effective learning among students and more rapidly lead them to greater competency and confidence?}
}

@comment{KKK}

@inproceedings{Kacsmar2022,
  doi = {10.1145/3564721.3564739},
  title = {Improving interactive instruction: Faculty engagement requires starting small and telling all},
  booktitle = {Koli Calling '22: 22nd Koli Calling International Conference on Computing Education Research},
  author = {Kacsmar, Bailey},
  publisher = {ACM},
  month = nov,
  year = {2022},
  conference = {Koli 2022: 22nd Koli Calling International Conference on Computing Education Research},
  abstract = {Interactive instruction, such as student-centered learning or active learning, is known to benefit student success as well as diversity in computer science. However, there is a persistent and substantial dissonance between research and practice of computer science education techniques. Current research on computer science education, while extensive, sees limited adoption beyond the original researchers. The developed educational technologies can lack sufficient detail for replication or be too specific and require extensive reworking to be employable by other instructors. Furthermore, instructors face barriers to adopting interactive techniques within their classroom due to student reception, resources, and awareness. We argue that the advancement of computer science education, in terms of propagation and sustainability of student-centered teaching, requires guided approaches for incremental instructional changes as opposed to revolutionary pedagogy. This requires the prioritization of lightweight techniques that can fit within existing lecture formats to enable instructors to overcome barriers hindering the adoption of interactive techniques. Furthermore, such techniques and innovations must be documented in the form of computing education research artifacts, building upon the practices of software artifacts.}
}

@article{Khan2022,
  doi = {10.1109/tse.2021.3082068},
  url = {https://doi.org/10.1109/tse.2021.3082068},
  year = {2022},
  month = aug,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {48},
  number = {8},
  pages = {3145--3158},
  author = {Faizan Khan and Boqi Chen and Daniel Varro and Shane McIntosh},
  title = {An Empirical Study of Type-Related Defects in Python Projects},
  journal = {{IEEE} Transactions on Software Engineering}
}

@article{Kohavi2009,
  doi = {10.1007/s10618-008-0114-1},
  title = {Controlled experiments on the web: survey and practical guide},
  author = {Kohavi, Ron and Longbotham, Roger and Sommerfield, Dan and Henne, Randal M},
  journal = {Data Min. Knowl. Discov.},
  publisher = {Springer Science and Business Media LLC},
  volume = {18},
  number = {1},
  pages = {140--181},
  month = feb,
  year = {2009},
  copyright = {https://creativecommons.org/licenses/by-nc/2.0},
  abstract = {}
}

@misc{Kudrjavets2022,
  author = {Gunnar Kudrjavets and Nachiappan Nagappan and Ayushi Rastogi},
  title = {Do Small Code Changes Merge Faster? A Multi-Language Empirical Investigation},
  year = {2022},
  eprint = {arXiv:2203.05045},
  doi = {10.1145/3524842.3528448},
}

@article{Kuhrmann2022,
  doi = {10.1109/tse.2021.3099532},
  url = {https://doi.org/10.1109/tse.2021.3099532},
  year = {2022},
  month = sep,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {48},
  number = {9},
  pages = {3523--3539},
  author = {Marco Kuhrmann and Paolo Tell and Regina Hebig and Jil Klunder and Jurgen Munch and Oliver Linssen and Dietmar Pfahl and Michael Felderer and Christian R. Prause and Stephen G. MacDonell and Joyce Nakatumba-Nabende and David Raffo and Sarah Beecham and Eray Tuzun and Gustavo Lopez and Nicolas Paez and Diego Fontdevila and Sherlock A. Licorish and Steffen Kupper and Gunther Ruhe and Eric Knauss and Ozden Ozcan-Top and Paul Clarke and Fergal McCaffery and Marcela Genero and Aurora Vizcaino and Mario Piattini and Marcos Kalinowski and Tayana Conte and Rafael Prikladnicki and Stephan Krusche and Ahmet Coskuncay and Ezequiel Scott and Fabio Calefato and Svetlana Pimonova and Rolf-Helge Pfeiffer and Ulrik Pagh Schultz and Rogardt Heldal and Masud Fazal-Baqaie and Craig Anslow and Maleknaz Nayebi and Kurt Schneider and Stefan Sauer and Dietmar Winkler and Stefan Biffl and Maria Cecilia Bastarrica and Ita Richardson},
  title = {What Makes Agile Software Development Agile?},
  journal = {{IEEE} Transactions on Software Engineering}
}

@misc{Kula2022,
  author = {Raula Gaikovina Kula and Christoph Treude},
  title = {In War and Peace: The Impact of World Politics on Software Ecosystems},
  year = {2022},
  eprint = {arXiv:2208.01393},
}

@inproceedings{Kumar2022,
  doi = {10.1145/3524610.3528389},
  title = {On the developers' attitude towards {CRAN} checks},
  booktitle = icpc,
  author = {Kumar, Pranjay and Ie, Davin and Vidoni, Melina},
  publisher = {ACM},
  month = may,
  year = {2022},
  conference = icpc,
  abstract = {R is a package-based, multi-paradigm programming language for scientific software. It provides an easy way to install third-party code, datasets, tests, documentation and examples through CRAN (Comprehensive R Archive Network). Prior works indicated developers tend to code workarounds to bypass CRAN's automated checks (performed when submitting a package) instead of fixing the code-doing so reduces packages' quality. It may become a threat to those analyses written in R that rely on miss-checked code. This preliminary study card-sorted source code comments and analysed StackOverflow (SO) conversations discussing CRAN checks to understand developers' attitudes. We determined that about a quarter of SO posts aim to bypass a check with a workaround; the most affected are code-related problems, package dependencies, installation and feasibility. We analyse these checks and outline future steps to improve similar automated analyses.}
}

@article{Kuttal2021,
  doi = {10.1016/j.infsof.2021.106633},
  url = {https://doi.org/10.1016/j.infsof.2021.106633},
  year = {2021},
  month = oct,
  publisher = {Elsevier {BV}},
  volume = {138},
  pages = {106633},
  author = {Sandeep Kaur Kuttal and Xiaofan Chen and Zhendong Wang and Sogol Balali and Anita Sarma},
  title = {Visual Resume: Exploring developers' online contributions for hiring},
  journal = {Information and Software Technology},
  abstract = {Context: Recruiters and practitioners are increasingly relying on online activities of developers to find a suitable candidate. Past empirical studies have identified technical and soft skills that managers use in online peer production sites when making hiring decisions. However, finding candidates with relevant skills is a labor-intensive task for managers, due to the sheer amount of information online peer production sites contain. Objective: We designed a profile aggregation tool---Visual Resume---that aggregates contribution information across two types of peer production sites: a code hosting site (GitHub) and a technical Q\&A forum (Stack Overflow). Visual Resume displays summaries of developers' contributions and allows easy access to their contribution details. It also facilitates pairwise comparisons of candidates through a card-based design. We present the motivation for such a design and design guidelines for creating such recruitment tool.
Methods: We performed a scenario-based evaluation to identify how participants use developers' online contributions in peer production sites as well as how they used Visual Resume when making hiring decisions. Results: Our analysis helped in identifying the technical and soft skill cues that were most useful to our participants when making hiring decisions in online production sites. We also identified the information features that participants used and the ways the participants accessed that information to select a candidate. Conclusions: Our results suggest that Visual Resume helps in participants evaluate cues for technical and soft skills more efficiently as it presents an aggregated view of candidate's contributions, allows drill down to details about contributions, and allows easy comparison of candidates via movable cards that could be arranged to match participants' needs.}
}

@comment{LLL}

@inproceedings{Lamba2020,
  doi = {10.1145/3368089.3409705},
  url = {https://doi.org/10.1145/3368089.3409705},
  year = {2020},
  month = nov,
  publisher = {{ACM}},
  author = {Hemank Lamba and Asher Trockman and Daniel Armanios and Christian K\"{a}stner and Heather Miller and Bogdan Vasilescu},
  title = {Heard it through the Gitvine: an empirical study of tool diffusion across the npm ecosystem},
  booktitle = esec-fse,
  abstract = {Automation tools like continuous integration services, code coverage reporters, style checkers, dependency managers, etc. are all known to provide significant improvements in developer productivity and software quality. Some of these tools are widespread, others are not. How do these automation ``best practices'' spread? And how might we facilitate the diffusion process for those that have seen slower adoption? In this paper, we rely on a recent innovation in transparency on code hosting platforms like GitHub---the use of repository badges---to track how automation tools spread in open-source ecosystems through different social and technical mechanisms over time. Using a large longitudinal data set, multivariate network science techniques, and survival analysis, we study which socio-technical factors can best explain the observed diffusion process of a number of popular automation tools. Our results show that factors such as social exposure, competition, and observability affect the adoption of tools significantly, and they provide a roadmap for software engineers and researchers seeking to propagate best practices and tools.}
}

@misc{Langhout2021,
  author = {Chris Langhout and Maurício Aniche},
  title = {Atoms of Confusion in Java},
  year = {2021},
  eprint = {arXiv:2103.05424},
}

@article{LawrenceDill2022,
  doi = {10.1371/journal.pcbi.1009957},
  title = {Ten simple rules to ruin a collaborative environment},
  author = {Lawrence-Dill, Carolyn J and Allscheid, Robyn L and Boaitey, Albert and Bauman, Todd and Buckler, 4th, Edward S and Clarke, Jennifer L and Cullis, Christopher and Dekkers, Jack and Dorius, Cassandra J and Dorius, Shawn F and Ertl, David and Homann, Matthew and Hu, Guiping and Losch, Mary and Lyons, Eric and Murdoch, Brenda and Navabi, Zahra-Katy and Punnuri, Somashekhar and Rafiq, Fahad and Reecy, James M and Schnable, Patrick S and Scott, Nicole M and Sheehan, Moira and Sirault, Xavier and Staton, Margaret and Tuggle, Christopher K and Van Eenennaam, Alison and Voas, Rachael},
  journal = {PLoS Comput. Biol.},
  publisher = {Public Library of Science (PLoS)},
  volume = {18},
  number = {4},
  pages = {e1009957},
  month = apr,
  year = {2022},
  copyright = {http://creativecommons.org/licenses/by/4.0/},
  abstract = {}
}

@misc{Leelaprute2022,
  author = {Pattara Leelaprute and Bodin Chinthanet and Supatsara Wattanakriengkrai and Raula Gaikovina Kula and Pongchai Jaisri and Takashi Ishio},
  title = {Does Coding in Pythonic Zen Peak Performance? Preliminary Experiments of Nine Pythonic Idioms at Scale},
  year = {2022},
  eprint = {arXiv:2203.14484},
}

@misc{Leinonen2022,
  author = {Juho Leinonen and Arto Hellas and Sami Sarsa and Brent Reeves and Paul Denny and James Prather and Brett A. Becker},
  title = {Using Large Language Models to Enhance Programming Error Messages},
  year = {2022},
  eprint = {arXiv:2210.11630},
}

@misc{Leven2022,
  author = {William Levén and Hampus Broman and Terese Besker and Richard Torkar},
  title = {The Broken Windows Theory Applies to Technical Debt},
  year = {2022},
  eprint = {arXiv:2209.01549},
}

@inproceedings{Li2019,
  doi = {10.1145/3286960.3286970},
  title = {Towards a framework for teaching debugging},
  booktitle = {Proceedings of the {Twenty-First} Australasian Computing Education Conference on - {ACE} '19},
  author = {Li, Chen and Chan, Emily and Denny, Paul and Luxton-Reilly, Andrew and Tempero, Ewan},
  publisher = {ACM Press},
  year = {2019},
  copyright = {http://www.acm.org/publications/policies/copyright\_policy\#Background},
  conference = {the Twenty-First Australasian Computing Education Conference},
  abstract = {Debugging is an important component of software development, yet most novice programmers are not explicitly taught to apply systematic strategies or processes for debugging. In this paper we adapt a framework developed for teaching troubleshooting to the debugging domain, and explore how the literature on teaching debugging maps to this framework. We identify debugging processes that are fundamental for novices to learn, aspects of debugging that novices typically struggle to develop, and shortcomings of tools designed to support teaching of debugging.}
}

@inproceedings{Li2022,
  doi = {10.1145/3510456.3514147},
  url = {https://doi.org/10.1145/3510456.3514147},
  year = {2022},
  month = may,
  publisher = {{ACM}},
  author = {Annie Li and Madeline Endres and Westley Weimer},
  title = {Debugging with stack overflow},
  booktitle = {Proceedings of the {ACM}/{IEEE} 44th International Conference on Software Engineering: Software Engineering Education and Training}
}

@inproceedings{Liang2022,
  doi = {10.1145/3540250.3549082},
  title = {Understanding skills for {OSS} communities on {GitHub}},
  booktitle = esec-fse,
  author = {Liang, Jenny T and Zimmermann, Thomas and Ford, Denae},
  publisher = {ACM},
  month = nov,
  year = {2022},
  conference = esec-fse,
  abstract = {The development of open source software (OSS) is a broad field which requires diverse skill sets. For example, maintainers help lead the project and promote its longevity, technical writers assist with documentation, bug reporters identify defects in software, and developers program the software. However, it is unknown which skills are used in OSS development as well as OSS contributors' general attitudes towards skills in OSS. In this paper, we address this gap by administering a survey to a diverse set of 455 OSS contributors. Guided by these responses as well as prior literature on software development expertise and social factors of OSS, we develop a model of skills in OSS that considers the many contexts OSS contributors work in. This model has 45 skills in the following 9 categories: technical skills, working styles, problem solving, contribution types, project-specific skills, interpersonal skills, external relations, management, and characteristics. Through a mix of qualitative and quantitative analyses, we find that OSS contributors are actively motivated to improve skills and perceive many benefits in sharing their skills with others. We then use this analysis to derive a set of design implications and best practices for those who incorporate skills into OSS tools and platforms, such as GitHub.}
}

@article{Liu2022,
  doi = {10.1145/3576036},
  url = {https://doi.org/10.1145/3576036},
  year = {2022},
  month = dec,
  publisher = {Association for Computing Machinery ({ACM})},
  author = {Eric S. Liu and Dylan A. Lukes and William G. Griswold},
  title = {Refactoring in Computational Notebooks},
  journal = {{ACM} Transactions on Software Engineering and Methodology}
}

@inproceedings{Lorey2022,
  doi = {10.1145/3510003.3510076},
  url = {https://doi.org/10.1145/3510003.3510076},
  year = {2022},
  month = may,
  publisher = {{ACM}},
  author = {Tobias Lorey and Paul Ralph and Michael Felderer},
  title = {Social science theories in software engineering research},
  booktitle = {Proceedings of the 44th International Conference on Software Engineering}
}

@article{Lu2021,
  doi = {10.22152/programming-journal.org/2022/6/8},
  title = {Types for tables: A language design benchmark},
  author = {Lu, Kuang-Chen and Greenman, Ben and Krishnamurthi, Shriram},
  journal = {Art Sci. Eng. Program.},
  publisher = {Aspect-Oriented Software Association (AOSA)},
  volume = {6},
  number = {2},
  month = nov,
  year = {2021},
  abstract = {Context Tables are ubiquitous formats for data. Therefore, techniques for writing correct programs over tables, and debugging incorrect ones, are vital. Our speciﬁc focus in this paper is on rich types that articulate the properties of tabular operations. We wish to study both their expressive power and diagnostic quality . Inquiry There is no “standard library” of table operations. As a result, every paper (and project) is free to use its own (sub)set of operations. This makes artifacts very diﬃcult to compare, and it can be hard to tell whether omitted operations were left out by oversight or because they cannot actually be expressed. Furthermore, virtually no papers discuss the quality of type error feedback. Approach We combed through several existing languages and libraries to create a “standard library” of table operations. Each entry is accompanied by a detailed speciﬁcation of its “type,” expressed independent of (and hence not constrained by) any type language. We also studied and categorized a corpus of (student) program edits that resulted in table-related errors. We used this to generate a suite of erroneous programs. Finally, we adapted the concept of a datasheet to facilitate comparisons of diﬀerent implementations. Knowledge Our benchmark creates a common ground to frame work in this area. Language designers who claim to support typed programming over tables have a clear suite against which to demonstrate their system’s expressive power. Our family of errors also gives them a chance to demonstrate the quality of feedback. Researchers who improve one aspect—especially error reporting—without changing the other can demonstrate their improvement, as can those who engage in trade-oﬀs between the two. The net result should be much better science in both expressiveness and diagnostics. We also introduce a datasheet format for presenting this knowledge in a methodical way. ubiquitous, and the expressive power of type systems keeps growing. Our benchmark and datasheet can help lead to more orderly science. It also beneﬁts programmers trying to choose a language.}
}

@inproceedings{Luders2022,
  doi = {10.1145/3524842.3528457},
  title = {Beyond duplicates},
  booktitle = msr,
  author = {L{\"u}ders, Clara Marie and Bouraffa, Abir and Maalej, Walid},
  publisher = {ACM},
  month = may,
  year = {2022},
  abstract = {Software projects use Issue Tracking Systems (ITS) like JIRA to track issues and organize the workflows around them. Issues are often inter-connected via different links such as the default JIRA link types Duplicate, Relate, Block, or Subtask. While previous research has mostly focused on analyzing and predicting duplication links, this work aims at understanding the various other link types, their prevalence, and characteristics towards a more reliable link type prediction. For this, we studied 607,208 links connecting 698,790 issues in 15 public JIRA repositories. Besides the default types, the custom types Depend, Incorporate, Split, and Cause were also common. We manually grouped all 75 link types used in the repositories into five general categories: General Relation, Duplication, Composition, Temporal/Causal, and Workflow. Comparing the structures of the corresponding graphs, we observed several trends. For instance, Duplication links tend to represent simpler issue graphs often with two components and Composition links present the highest amount of hierarchical tree structures (97.7\%). Surprisingly, General Relation links have a significantly higher transitivity score than Duplication and Temporal/ Causal links. Motivated by the differences between the link types and by their popularity, we evaluated the robustness of two state-of-the-art duplicate detection approaches from the literature on the JIRA dataset. We found that current deep-learning approaches confuse between Duplication and other links in almost all repositories. On average, the classification accuracy dropped by 6\% for one approach and 12\% for the other. Extending the training sets with other link types seems to partly solve this issue. We discuss our findings and their implications for research and practice.}
}

@inproceedings{Lunn2021,
  doi = {10.1145/3430665.3456362},
  url = {https://doi.org/10.1145/3430665.3456362},
  year = {2021},
  month = jun,
  publisher = {{ACM}},
  author = {Stephanie Lunn and Monique Ross and Zahra Hazari and Mark Allen Weiss and Michael Georgiopoulos and Kenneth Christensen},
  title = {The Impact of Technical Interviews,  and other Professional and Cultural Experiences on Students{\textquotesingle} Computing Identity},
  booktitle = {Proceedings of the 26th {ACM} Conference on Innovation and Technology in Computer Science Education V. 1}
}

@comment{MMM}

@misc{MacNeil2022,
  author = {Stephen MacNeil and Andrew Tran and Arto Hellas and Joanne Kim and Sami Sarsa and Paul Denny and Seth Bernstein and Juho Leinonen},
  title = {Experiences from Using Code Explanations Generated by Large Language Models in a Web Software Development E-Book},
  year = {2022},
  eprint = {arXiv:2211.02265},
}

@article{Martin2023,
  doi = {10.1016/j.iheduc.2022.100879},
  title = {Bichronous online learning: Award-winning online instructor practices of blending asynchronous and synchronous online modalities},
  author = {Martin, Florence and Kumar, Swapna and Ritzhaupt, Albert D and Polly, Drew},
  journal = {Internet High. Educ.},
  publisher = {Elsevier BV},
  volume = {56},
  number = {100879},
  pages = {100879},
  month = jan,
  year = {2023},
  abstract = {}
}

@article{Mashey2021,
  doi = {10.1109/mm.2021.3112876},
  url = {https://doi.org/10.1109/mm.2021.3112876},
  year = {2021},
  month = nov,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {41},
  number = {6},
  pages = {131--139},
  author = {John R. Mashey},
  title = {Interactions,  Impacts,  and Coincidences of the First Golden Age of Computer Architecture},
  journal = {{IEEE} Micro}
}

@misc{Matsubara2022,
  author = {Patricia G. F. Matsubara and Igor Steinmacher and Bruno Gadelha and Tayana Conte},
  title = {The best defense is a good defense: adapting negotiation methods for tackling pressure over software project estimates},
  year = {2022},
  eprint = {arXiv:2203.13623},
  doi = {10.1145/3510455.3512775},
}

@article{May2019,
  doi = {10.1007/s10664-019-09685-x},
  url = {https://doi.org/10.1007/s10664-019-09685-x},
  year = {2019},
  month = feb,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {24},
  number = {4},
  pages = {1997--2019},
  author = {Anna May and Johannes Wachs and Anik\'{o} Hann\'{a}k},
  title = {Gender differences in participation and reward on Stack Overflow},
  journal = ese,
  abstract = {Programming is a valuable skill in the labor market, making the underrepresentation of women in computing an increasingly important issue. Online question and answer platforms serve a dual purpose in this field: they form a body of knowledge useful as a reference and learning tool, and they provide opportunities for individuals to demonstrate credible, verifiable expertise. Issues, such as male-oriented site design or overrepresentation of men among the site's elite may therefore compound the issue of women's underrepresentation in IT. In this paper we audit the differences in behavior and outcomes between men and women on Stack Overflow, the most popular of these Q\&A sites. We observe significant differences in how men and women participate in the platform and how successful they are. For example, the average woman has roughly half of the reputation points, the primary measure of success on the site, of the average man. Using an Oaxaca-Blinder decomposition, an econometric technique commonly applied to analyze differences in wages between groups, we find that most of the gap in success between men and women can be explained by differences in their activity on the site and differences in how these activities are rewarded. Specifically, 1) men give more answers than women and 2) are rewarded more for their answers on average, even when controlling for possible confounders such as tenure or buy-in to the site. Women ask more questions and gain more reward per question. We conclude with a hypothetical redesign of the site's scoring system based on these behavioral differences, cutting the reputation gap in half.}
}

@article{Mehrpour2022,
  doi = {10.1007/s10664-022-10232-4},
  url = {https://doi.org/10.1007/s10664-022-10232-4},
  year = {2022},
  month = nov,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {28},
  number = {1},
  author = {Sahar Mehrpour and Thomas D. LaToza},
  title = {Can static analysis tools find more defects?},
  journal = {Empirical Software Engineering}
}

@inproceedings{Miedema2022,
  doi = {10.1145/3524610.3529158},
  title = {So many brackets!},
  booktitle = icpc,
  author = {Miedema, Daphne and Fletcher, George and Aivaloglou, Efthimia},
  publisher = {ACM},
  month = may,
  year = {2022},
  conference = icpc,
  abstract = {The Structured Query Language (SQL) is a widely taught database query language in computer science, data science, and software engineering programs. While highly expressive, SQL is challenging to learn for novices. Various research has explored the errors and mistakes that SQL users make. Specific attributes of SQL code, such as the number of tables and the degree of nesting, have been found to impact its understandability and maintainability. Furthermore, prior studies have shown that novices have significant issues using SQL correctly, due to factors such as expressive ease, existing knowledge and misconceptions, and the impact of cognitive load. In this paper we identify another factor: self-inflicted query complexity, where users hinder their own problem solving process. We analyse 8K intermediate and final student attempts to six SQL exer-cises, approaching complexity from four perspective: correctness, execution order, edit distance and query intricacy. Through our analyses, we find that our students are hindered in their query formulation process by mismanaging complexity through writing overly elaborate queries containing unnecessary elements, overusing brackets and nesting, and incrementally building queries with persistent errors.}
}

@comment{NNN}

@article{NandSharma2022,
  doi = {10.1002/spe.3128},
  title = {Unearthing open source decision-making processes: A case study of {Python} enhancement proposals},
  author = {{Nand Sharma}, Pankajeshwara and Tony Roy Savarimuthu, Bastin and Stanger, Nigel},
  journal = {Softw. Pract. Exp.},
  publisher = {Wiley},
  volume = {52},
  number = {10},
  pages = {2312--2346},
  month = oct,
  year = {2022},
  copyright = {http://creativecommons.org/licenses/by-nc/4.0/},
  abstract = {Good governance practices are pivotal to the success of Open Source Software (OSS) projects. However, the decision‐making processes that are made available to stakeholders are at times incomplete and may remain buried and hidden in large amounts of software repository data. This work bridges this gap by unearthing enacted decision‐making processes available for Python Enhancement Proposals (PEPs) from 1.54 million email messages that embody decisions made during the evolution of the Python language. This work employs a design science approach in operationalizing a framework called DeMaP miner that is used to discover hidden processes using information retrieval and information extraction techniques. It also uses process mining techniques to visualize the processes, and comparative structural analysis techniques to compare different decision processes. The work identifies a richer set of decision‐making activities than those reported on the Python website and in prior research work (48 new decision activities, 199 new pathways and 6 new stages). The extracted decision process has been positively evaluated by a prominent member of the Python steering council. The extracted process can be used for process compliance checking and process improvement in OSS communities. Additionally, the DeMaP Miner framework can be extended and customized to suit other OSS projects, such as the OpenJDK project.}
}

@inproceedings{Nguyen2022,
  doi = {10.1145/3524842.3528470},
  title = {An empirical evaluation of {GitHub} copilot's code suggestions},
  booktitle = msr,
  author = {Nguyen, Nhan and Nadi, Sarah},
  publisher = {ACM},
  month = may,
  year = {2022},
  abstract = {GitHub and OpenAI recently launched Copilot, an “AI pair programmer” that utilizes the power of Natural Language Processing, Static Analysis, Code Synthesis, and Artificial Intelligence. Given a natural language description of the target functionality, Copilot can generate corresponding code in several programming languages. In this paper, we perform an empirical study to evaluate the correctness and understandability of Copilot's suggested code. We use 33 LeetCode questions to create queries for Copilot in four different programming languages. We evaluate the correctness of the corresponding 132 Copilot solutions by running LeetCode's provided tests, and evaluate understandability using SonarQube's cyclomatic complexity and cognitive complexity metrics. We find that Copilot's Java suggestions have the highest correctness score (57\%) while JavaScript is the lowest (27\%). Overall, Copilot's suggestions have low complexity with no notable differences between the programming languages. We also find some potential Copilot shortcomings, such as generating code that can be further simplified and code that relies on undefined helper methods.}
}

@misc{Nicacio2022,
  author = {Jalves Nicacio and Fabio Petrillo},
  title = {An Approach to Build Consistent Software Architecture Diagrams Using Devops System Descriptors},
  year = {2022},
  eprint = {arXiv:2210.11910},
  doi = {10.1145/3550356.3561567},
}

@misc{Noble2022,
  author = {James Noble and David Streader and Isaac Oscar Gariano and Miniruwani Samarakoon},
  title = {More Programming Than Programming: Teaching Formal Methods in a Software Engineering Programme},
  year = {2022},
  eprint = {arXiv:2205.00787},
}

@comment{OOO}

@article{Olejniczak2020,
  doi = {10.1162/qss_a_00091},
  url = {https://doi.org/10.1162/qss_a_00091},
  year = {2020},
  month = dec,
  publisher = {{MIT} Press - Journals},
  volume = {1},
  number = {4},
  pages = {1429--1450},
  author = {Anthony J. Olejniczak and Molly J. Wilson},
  title = {Who's writing open access ({OA}) articles? Characteristics of {OA} authors at Ph.D.-granting institutions in the United States},
  journal = {Quantitative Science Studies},
  abstract = {The open access (OA) publication movement aims to present research literature to the public at no cost and with no restrictions. While the democratization of access to scholarly literature is a primary focus of the movement, it remains unclear whether OA has uniformly democratized the corpus of freely available research, or whether authors who choose to publish in OA venues represent a particular subset of scholars---those with access to resources enabling them to afford article processing charges (APCs). We investigated the number of OA articles with article processing charges (APC OA) authored by 182,320 scholars with known demographic and institutional characteristics at American research universities across 11 broad fields of study. The results show, in general, that the likelihood for a scholar to author an APC OA article increases with male gender, employment at a prestigious institution (AAU member universities), association with a STEM discipline, greater federal research funding, and more advanced career stage (i.e., higher professorial rank). Participation in APC OA publishing appears to be skewed toward scholars with greater access to resources and job security.}
}

@comment{PPP}

@article{Palomba2021,
  doi = {10.1109/tse.2018.2883603},
  url = {https://doi.org/10.1109/tse.2018.2883603},
  year = {2021},
  month = jan,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {1},
  pages = {108--129},
  author = {Fabio Palomba and Damian Andrew Tamburri and Francesca Arcelli Fontana and Rocco Oliveto and Andy Zaidman and Alexander Serebrenik},
  title = {Beyond Technical Aspects: How Do Community Smells Influence the Intensity of Code Smells?},
  journal = ieee-tse,
  abstract = {Code smells are poor implementation choices applied by developers during software evolution that often lead to critical flaws or failure. Much in the same way, community smells reflect the presence of organizational and socio-technical issues within a software community that may lead to additional project costs. Recent empirical studies provide evidence that community smells are often---if not always---connected to circumstances such as code smells. In this paper we look deeper into this connection by conducting a mixed-methods empirical study of 117 releases from 9 open-source systems. The qualitative and quantitative sides of our mixed-methods study were run in parallel and assume a mutually-confirmative connotation. On the one hand, we survey 162 developers of the 9 considered systems to investigate whether developers perceive relationship between community smells and the code smells found in those projects. On the other hand, we perform a fine-grained analysis into the 117 releases of our dataset to measure the extent to which community smells impact code smell intensity (i.e., criticality). We then propose a code smell intensity prediction model that relies on both technical and community-related aspects. The results of both sides of our mixed-methods study lead to one conclusion: community-related factors contribute to the intensity of code smells. This conclusion supports the joint use of community and code smells detection as a mechanism for the joint management of technical and social problems around software development communities.}
}

@article{Pelanek2022,
  doi = {10.1145/3578269},
  url = {https://doi.org/10.1145/3578269},
  year = {2022},
  month = dec,
  publisher = {Association for Computing Machinery ({ACM})},
  author = {Radek Pel{\'{a}}nek and Tom{\'{a}}{\v{s}} Effenberger},
  title = {The Landscape of Computational Thinking Problems for Practice and Assessment},
  journal = {{ACM} Transactions on Computing Education}
}

@inproceedings{Pereira2017,
  doi = {10.1145/3136014.3136031},
  title = {Energy efficiency across programming languages: how do energy, time, and memory relate?},
  booktitle = {Proceedings of the 10th {ACM} {SIGPLAN} International Conference on Software Language Engineering},
  author = {Pereira, Rui and Couto, Marco and Ribeiro, Francisco and Rua, Rui and Cunha, J{\'a}come and Fernandes, Jo{\~a}o Paulo and Saraiva, Jo{\~a}o},
  publisher = {ACM},
  month = oct,
  year = {2017},
  copyright = {http://www.acm.org/publications/policies/copyright\_policy\#Background},
  conference = splash,
  abstract = {This paper presents a study of the runtime, memory usage and energy consumption of twenty seven well-known software languages. We monitor the performance of such languages using ten different programming problems, expressed in each of the languages. Our results show interesting findings, such as, slower/faster languages consuming less/more energy, and how memory usage influences energy consumption. Finally, we show how to use our results to provide software engineers support to decide which language to use when energy efficiency is a concern.}
}

@misc{Pinckney2022,
  author = {Donald Pinckney and Federico Cassano and Arjun Guha and Jon Bell and Massimiliano Culpo and Todd Gamblin},
  title = {Flexible and Optimal Dependency Management via Max-SMT},
  year = {2022},
  eprint = {arXiv:2203.13737},
}

@misc{Pinto2022,
  author = {Gustavo Pinto and Alberto de Souza},
  title = {Cognitive-Driven Development Helps Software Teams to Keep Code Units Under the Limit!},
  year = {2022},
  eprint = {arXiv:2210.07342},
}

@misc{Pizard2022,
  author = {Sebasti\'{a}n Pizard and Diego Vallespir and Barbara Kitchenham},
  title = {A longitudinal case study on the effects of an evidence-based software engineering training},
  year = {2022},
  eprint = {arXiv:2202.03367},
  doi = {10.1145/3510456.3514150},
}

@article{Poulos2021,
  doi = {10.1002/spe.3022},
  url = {https://doi.org/10.1002/spe.3022},
  year = {2021},
  month = sep,
  publisher = {Wiley},
  volume = {52},
  number = {2},
  pages = {619--635},
  author = {Alexandra Poulos and Sally A. McKee and Jon C. Calhoun},
  title = {Posits and the state of numerical representations in the age of exascale and edge computing},
  journal = {Software: Practice and Experience},
  abstract = {Growing constraints on memory utilization, power consumption, and I/O throughput have increasingly become limiting factors to the advancement of high performance computing (HPC) and edge computing applications. IEEE-754 floating-point types have been the de facto standard for floating-point number systems for decades, but the drawbacks of this numerical representa- tion leave much to be desired. Alternative representations are gaining traction, both in HPC and machine learning environments. Posits have recently been proposed as a drop-in replacement for the IEEE-754 floating-point representa- tion. We survey the state-of-the-art and state-of-the-practice in the development and use of posits in edge computing and HPC. The current literature supports posits as a promising alternative to traditional floating-point systems, both as a stand-alone replacement and in a mixed-precision environment. Development and standardization of the posit type is ongoing, and much research remains to explore the application of posits in different domains, how to best implement them in hardware, and where they fit with other numerical representations.}
}

@article{Prana2019,
  doi = {10.1007/s10664-018-9660-3},
  title = {Categorizing the content of {GitHub} {README} files},
  author = {Prana, Gede Artha Azriadi and Treude, Christoph and Thung, Ferdian and Atapattu, Thushari and Lo, David},
  journal = {Empir. Softw. Eng.},
  publisher = {Springer Science and Business Media LLC},
  volume = {24},
  number = {3},
  pages = {1296--1327},
  month = jun,
  year = {2019},
  abstract = {}
}

@inproceedings{PreslerMarshall2022a,
  doi = {10.1145/3478431.3499367},
  title = {Identifying struggling teams in software engineering courses through weekly surveys},
  booktitle = sigcse,
  author = {Presler-Marshall, Kai and Heckman, Sarah and Stolee, Kathryn T},
  publisher = {ACM},
  month = feb,
  year = {2022},
  copyright = {http://www.acm.org/publications/policies/copyright\_policy\#Background},
  conference = sigcse,
  abstract = {Teaming is increasingly a core aspect of professional software engineering and most undergraduate computer science curricula. At NC State University, we teach communication and project-management skills explicitly through a junior-level software engineering course. However, some students may have a dysfunctional team experience that imperils their ability to learn these skills. Identifying these teams during a team project is important so the teaching staff can intervene early and hopefully alleviate the issues. We propose a weekly reflection survey to help the course teaching staff proactively identify teams that may not be on track to learn the course outcomes. The questions on the survey focus on team communication and collaboration over the previous week. We evaluate our survey on two semesters of the undergraduate software engineering course by comparing teams with poor end-of-project grades or peer evaluations against teams flagged on a weekly basis through the surveys. We find that the survey can identify most teams that later struggled on the project, typically by the half-way mark of the project, and thus may provide instructors with an actionable early-warning about struggling teams. Furthermore, a majority of students (64.4\%) found the survey to be a helpful tool for keeping their team on track. Finally, we discuss future work for improving the survey and engaging with student teams.}
}

@inproceedings{PreslerMarshall2022b,
  doi = {10.1145/3501385.3543980},
  title = {What makes team[s] work? A study of team characteristics in software engineering projects},
  booktitle = icer,
  author = {Presler-Marshall, Kai and Heckman, Sarah and Stolee, Kathryn T},
  publisher = {ACM},
  month = aug,
  year = {2022},
  conference = icer,
  abstract = {Teaming is a core component in practically all professional software engineering careers, and as such, is a key skill taught in many undergraduate Computer Science programs. However, not all teams manage to work together effectively, and in education, this can deprive some students of successful teaming experiences. In this work, we seek to gain insights into the characteristics of successful and unsuccessful undergraduate student teams in a software engineering course. We conduct semi-structured interviews with 18 students who have recently completed a team-based software engineering course to understand how they worked together, what challenges they faced, and how they tried to overcome these challenges. Our results show that common problems include communicating, setting and holding to deadlines, and effectively identifying tasks and their relative difficulty. Additionally, we find that self-reflection on what is working and not working or external motivators such as grades help some, but not all, teams overcome these challenges. Finally, we conclude with recommendations for educators on successful behaviours to steer teams towards, and recommendations for researchers on future work to better understand challenges that teams face.}
}

@comment{QQQ}

@article{Qamar2022,
  doi = {10.1016/j.infsof.2022.106972},
  title = {Taxonomy of bug tracking process smells: Perceptions of practitioners and an empirical analysis},
  author = {Qamar, Khushbakht Ali and S{\"u}l{\"u}n, Emre and T{\"u}z{\"u}n, Eray},
  journal = {Inf. Softw. Technol.},
  publisher = {Elsevier BV},
  volume = {150},
  number = {106972},
  pages = {106972},
  month = oct,
  year = {2022},
  abstract = {}
}

@article{Queiroz2022,
  doi = {10.1080/21650349.2022.2088623},
  title = {Science as a game: conceptual model and application in scientific software design},
  author = {Queiroz, Francisco and Lonsdale, Maria and Spitz, Rejane},
  journal = {Int. j. des. creat. innov.},
  publisher = {Informa UK Limited},
  volume = {10},
  number = {4},
  pages = {222--246},
  month = oct,
  year = {2022},
  abstract = {ABSTRACT Scientific inquiry is often described as, and compared to, a game. This paper expands on that analogy to propose a conceptual model of scientific practice built upon Jesper Juul’s game definition, and informed by parallels between the two activities collected from selected works from history and philosophy of science. Moreover, the paper presents a design method, based on the model described, for fostering creative solutions in scientific software user interface design. Results from pilot case studies suggest both model and method are helpful, allowing participants to describe requirements and ideate solutions, as well providing a framework for the exploration of the game-science analogy within the context of scientific research conducted through computational resources.}
}

@comment{RRR}

@misc{Ragkhitwetsagul2022,
  author = {Chaiyong Ragkhitwetsagul and Matheus Paixao},
  title = {Recommending Code Improvements Based on Stack Overflow Answer Edits},
  year = {2022},
  eprint = {arXiv:2204.06773},
}

@inproceedings{Rahman2020b,
  doi = {10.1109/icsme46990.2020.00063},
  url = {https://doi.org/10.1109/icsme46990.2020.00063},
  year = {2020},
  month = sep,
  publisher = {{IEEE}},
  author = {Mohammad Masudur Rahman and Foutse Khomh and Marco Castelluccio},
  title = {Why are Some Bugs Non-Reproducible? An Empirical Investigation using Data Fusion},
  booktitle = icsme,
  abstract = {Software developers attempt to reproduce software bugs to understand their erroneous behaviours and to fix them. Unfortunately, they often fail to reproduce (or fix) them, which leads to faulty, unreliable software systems. However, to date, only a little research has been done to better understand what makes the software bugs non-reproducible. In this paper, we conduct a multimodal study to better understand the non-reproducibility of software bugs. First, we perform an empirical study using 576 non-reproducible bug reports from two popular software systems (Firefox, Eclipse) and identify 11 key factors that might lead a reported bug to non-reproducibility. Second, we conduct a user study involving 13 professional developers where we investigate how the developers cope with non-reproducible bugs. We found that they either close these bugs or solicit for further information, which involves long deliberations and counter-productive manual searches. Third, we offer several actionable insights on how to avoid non-reproducibility (e.g., false-positive bug report detector) and improve reproducibility of the reported bugs (e.g., sandbox for bug reproduction) by combining our analyses from multiple studies (e.g., empirical study, developer study).}
}

@article{Rahman2021,
  doi = {10.1145/3408897},
  url = {https://doi.org/10.1145/3408897},
  year = {2021},
  month = jan,
  publisher = {Association for Computing Machinery ({ACM})},
  volume = {30},
  number = {1},
  pages = {1--31},
  author = {Akond Rahman and Md Rayhanur Rahman and Chris Parnin and Laurie Williams},
  title = {Security Smells in Ansible and Chef Scripts},
  journal = acm-tosem,
  abstract = {Context: Security smells are recurring coding patterns that are indicative of security weakness and require further inspection. As infrastructure as code (IaC) scripts, such as Ansible and Chef scripts, are used to provision cloud-based servers and systems at scale, security smells in IaC scripts could be used to enable malicious users to exploit vulnerabilities in the provisioned systems. Goal: The goal of this article is to help practitioners avoid insecure coding practices while developing infrastructure as code scripts through an empirical study of security smells in Ansible and Chef scripts. Methodology: We conduct a replication study where we apply qualitative analysis with 1,956 IaC scripts to identify security smells for IaC scripts written in two languages: Ansible and Chef. We construct a static analysis tool called Security Linter for Ansible and Chef scripts (SLAC) to automatically identify security smells in 50,323 scripts collected from 813 open source software repositories. We also submit bug reports for 1,000 randomly selected smell occurrences. Results: We identify two security smells not reported in prior work: missing default in case statement and no integrity check. By applying SLAC we identify 46,600 occurrences of security smells that include 7,849 hard-coded passwords. We observe agreement for 65 of the responded 94 bug reports, which suggests the relevance of security smells for Ansible and Chef scripts amongst practitioners. Conclusion: We observe security smells to be prevalent in Ansible and Chef scripts, similarly to that of the Puppet scripts. We recommend practitioners to rigorously inspect the presence of the identified security smells in Ansible and Chef scripts using (i) code review, and (ii) static analysis tools.}
}

@misc{Rao2022,
  author = {Nikitha Rao and Jason Tsay and Martin Hirzel and Vincent J. Hellendoorn},
  title = {Comments on Comments: Where Code Review and Documentation Meet},
  year = {2022},
  eprint = {arXiv:2204.00107},
  doi = {10.1145/3524842.3528475},
}

@article{Ritschel2022a,
  doi = {10.1109/tse.2020.3027255},
  url = {https://doi.org/10.1109/tse.2020.3027255},
  year = {2022},
  month = may,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {48},
  number = {5},
  pages = {1630--1643},
  author = {Nico Ritschel and Vladimir Kovalenko and Reid Holmes and Ronald Garcia and David C. Shepherd},
  title = {Comparing Block-Based Programming Models for Two-Armed Robots},
  journal = {{IEEE} Transactions on Software Engineering}
}

@article{Ritschel2022b,
  doi = {10.1002/spe.3167},
  url = {https://doi.org/10.1002/spe.3167},
  year = {2022},
  month = nov,
  publisher = {Wiley},
  author = {Nico Ritschel and Anand Ashok Sawant and David Weintrop and Reid Holmes and Alberto Bacchelli and Ronald Garcia and Chandrika K R and Avijit Mandal and Patrick Francis and David C. Shepherd},
  title = {Training industrial end-user programmers with interactive tutorials},
  journal = {Software: Practice and Experience}
}

@article{Rule2019,
  doi = {10.1371/journal.pcbi.1007007},
  title = {Ten simple rules for writing and sharing computational analyses in Jupyter Notebooks},
  author = {Rule, Adam and Birmingham, Amanda and Zuniga, Cristal and Altintas, Ilkay and Huang, Shih-Cheng and Knight, Rob and Moshiri, Niema and Nguyen, Mai H and Rosenthal, Sara Brin and P{\'e}rez, Fernando and Rose, Peter W},
  journal = {PLoS Comput. Biol.},
  publisher = {Public Library of Science (PLoS)},
  volume = {15},
  number = {7},
  pages = {e1007007},
  month = jul,
  year = {2019},
  copyright = {http://creativecommons.org/licenses/by/4.0/},
  abstract = {1 Design Lab, UC San Diego, La Jolla, California, United States of America, 2 Center for Computational Biology and Bioinformatics, UC San Diego, La Jolla, California, United States of America, 3 Department of Pediatrics, UC San Diego, La Jolla, California, United States of America, 4 Data Science Hub, San Diego Supercomputer Center, UC San Diego, La Jolla, California, United States of America, 5 Departments of Bioengineering, and Computer Science and Engineering, and Center for Microbiome Innovation, UC San Diego, La Jolla, California, United States of America, 6 Bioinformatics and Systems Biology Graduate Program, UC San Diego, La Jolla, California, United States of America, 7 Department of Statistics and Berkeley Institute for Data Science, UC Berkeley, and Lawrence Berkeley National Laboratory, Berkeley, California, United States of America}
}

@comment{SSS}

@inproceedings{Sanders2019,
  doi = {10.1145/3291279.3339408},
  title = {Inferential statistics in computing education research},
  booktitle = icer,
  author = {Sanders, Kate and Sheard, Judy and Becker, Brett A and Eckerdal, Anna and Hamouda, Sally and {Simon}},
  publisher = {ACM},
  month = jul,
  year = {2019},
  copyright = {http://www.acm.org/publications/policies/copyright\_policy\#Background},
  conference = icer,
  abstract = {The goal of most computing education research is to effect positive change in how computing is taught and learned. Statistical techniques are one important tool for achieving this goal. In this paper we report on an analysis of ICER papers that use inferential statistics. We present the most commonly used techniques; an overview of the techniques the ICER community has used over its first 14 years of papers, grouped according to the purpose of the technique; and a detailed analysis of three of the most commonly used techniques (t-test, chi-squared test, and Mann-Whitney-Wilcoxon). We identify common flaws in reporting and give examples of papers where statistics are reported well. In sum, the paper draws a picture of the use of inferential statistics by the ICER community. This picture is intended to help orient researchers who are new to the use of statistics in computing education research and to encourage reflection by the ICER community on how it uses statistics and how it can improve that use.}
}

@inproceedings{Schmitt2022,
  doi = {10.1145/3563766.3564112},
  url = {https://doi.org/10.1145/3563766.3564112},
  year = {2022},
  month = nov,
  publisher = {{ACM}},
  author = {Paul Schmitt and Jana Iyengar and Christopher Wood and Barath Raghavan},
  title = {The decoupling principle},
  booktitle = {Proceedings of the 21st {ACM} Workshop on Hot Topics in Networks}
}

@article{Schurhoff2022,
  doi = {10.1007/s10664-022-10245-z},
  url = {https://doi.org/10.1007/s10664-022-10245-z},
  year = {2022},
  month = nov,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {28},
  number = {1},
  author = {Christian Sch\"{u}rhoff and Stefan Hanenberg and Volker Gruhn},
  title = {An empirical study on a single company's cost estimations of 338 software projects},
  journal = {Empirical Software Engineering}
}

@inproceedings{Sellitto2022,
  doi = {10.1109/saner53432.2022.00090},
  url = {https://doi.org/10.1109/saner53432.2022.00090},
  year = {2022},
  month = mar,
  publisher = {{IEEE}},
  author = {Giulia Sellitto and Emanuele Iannone and Zadia Codabux and Valentina Lenarduzzi and Andrea De Lucia and Fabio Palomba and Filomena Ferrucci},
  title = {Toward Understanding the Impact of Refactoring on Program Comprehension},
  booktitle = {2022 {IEEE} International Conference on Software Analysis,  Evolution and Reengineering ({SANER})}
}

@misc{Shankar2022,
  author = {Shreya Shankar and Rolando Garcia and Joseph M. Hellerstein and Aditya G. Parameswaran},
  title = {Operationalizing Machine Learning: An Interview Study},
  year = {2022},
  eprint = {arXiv:2209.09125},
}

@article{Sharafi2022,
  doi = {10.1109/tse.2020.3032064},
  url = {https://doi.org/10.1109/tse.2020.3032064},
  year = {2022},
  month = may,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {48},
  number = {5},
  pages = {1692--1704},
  author = {Zohreh Sharafi and Ian Bertram and Michael Flanagan and Westley Weimer},
  title = {Eyes on Code: A Study on Developers' Code Navigation Strategies},
  journal = {{IEEE} Transactions on Software Engineering}
}

@misc{Shimada2022,
  author = {Naomichi Shimada and Tao Xiao and Hideaki Hata and Christoph Treude and Kenichi Matsumoto},
  title = {GitHub Sponsors: Exploring a New Way to Contribute to Open Source},
  year = {2022},
  eprint = {arXiv:2202.05751},
  doi = {10.1145/3510003.3510116},
}

@inproceedings{Shome2022,
  doi = {10.1145/3522664.3528621},
  title = {Data smells in public datasets},
  booktitle = {Proceedings of the 1st International Conference on {AI} Engineering: Software Engineering for {AI}},
  author = {Shome, Arumoy and Cruz, Lu{\'\i}s and van Deursen, Arie},
  publisher = {ACM},
  month = may,
  year = {2022},
  conference = {CAIN '22: 1st Conference on AI Engineering - Software Engineering for AI},
  abstract = {The adoption of Artificial Intelligence (AI) in high-stakes domains such as healthcare, wildlife preservation, autonomous driving and criminal justice system calls for a data-centric approach to AI. Data scientists spend the majority of their time studying and wrangling the data, yet tools to aid them with data analysis are lacking. This study identifies the recurrent data quality issues in public datasets. Analogous to code smells, we introduce a novel catalogue of data smells that can be used to indicate early signs of problems or technical debt in machine learning systems. To understand the prevalence of data quality issues in datasets, we analyse 25 public datasets and identify 14 data smells.}
}

@inproceedings{Shrestha2021,
  doi = {10.1145/3472749.3474744},
  title = {Unravel: A Fluent Code Explorer for Data Wrangling},
  booktitle = {The 34th Annual {ACM} Symposium on User Interface Software and Technology},
  author = {Shrestha, Nischal and Barik, Titus and Parnin, Chris},
  publisher = {ACM},
  month = oct,
  year = {2021},
  conference = {UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology},
  abstract = {Data scientists have adopted a popular design pattern in programming called the fluent interface for composing data wrangling code. The fluent interface works by combining multiple transformations on a data table—or dataframes—with a single chain of expressions, which produces an output. Although fluent code promotes legibility, the intermediate dataframes are lost, forcing data scientists to unravel the chain through tedious code edits and re-execution. Existing tools for data scientists do not allow easy exploration or support understanding of fluent code. To address this gap, we designed a tool called Unravel that enables structural edits via drag-and-drop and toggle switch interactions to help data scientists explore and understand fluent code. Data scientists can apply simple structural edits via drag-and-drop and toggle switch interactions to reorder and (un)comment lines. To help data scientists understand fluent code, Unravel provides function summaries and always-on visualizations highlighting important changes to a dataframe. We discuss the design motivations behind Unravel and how it helps understand and explore fluent code. In a first-use study with 14 data scientists, we found that Unravel facilitated diverse activities such as validating assumptions about the code or data, exploring alternatives, and revealing function behavior.}
}

@inproceedings{Silva2022,
  doi = {10.1145/3502718.3524822},
  title = {{DBSnap-eval}},
  booktitle = iticse,
  author = {Silva, Yasin N and Loza, Alexis and Razente, Humberto},
  publisher = {ACM},
  month = jul,
  year = {2022},
  conference = iticse,
  abstract = {Learning to construct database queries can be a challenging task because students need to learn the specific query language syntax as well as properly understand the effect of each query operator and how multiple operators interact in a query. While some previous studies have looked into the types of database query errors students make and how the availability of expected query results can help to increase the success rate, there is very little that is known regarding the patterns that emerge while students are constructing a query. To be able to look into the process of constructing a query, in this paper we introduce DBSnap-Eval, a tool that supports tree-based queries (similar to SQL query plans) and a block-based querying interface to help separate the syntax and semantics of a query. DBSnap-Eval closely monitors the actions students take to construct a query such as adding a dataset or connecting a dataset with an operator. This paper presents an initial set of results about database query construction patterns using DBSnap-Eval. Particularly, it reports identified patterns in the process students follow to answer common database queries.}
}

@article{Soltani2020,
  doi = {10.1007/s10664-020-09882-z},
  title = {The significance of bug report elements},
  author = {Soltani, Mozhan and Hermans, Felienne and B{\"a}ck, Thomas},
  abstract = {AbstractOpen source software projects often use issue repositories, where project contributors submit bug reports. Using these repositories, more bugs in software projects may be identified and fixed. However, the content and therefore quality of bug reports vary. In this study, we aim to understand the significance of different elements in bug reports. We interviewed 35 developers to gain insights into their perceptions on the importance of various contents in bug reports. To assess our findings, we surveyed 305 developers. The results show developers find it highly important that bug reports include crash description, reproducing steps or test cases, and stack traces. Software version, fix suggestions, code snippets, and attached contents have lower importance for software debugging. Furthermore, to evaluate the quality of currently available bug reports, we mined issue repositories of 250 most popular projects on Github. Statistical analysis on the mined issues shows that crash reproducing steps, stack traces, fix suggestions, and user contents, have statistically significant impact on bug resolution times, for \~70\%, \~76\%, \~55\%, and \~33\% of the projects. However, on avarage, over 70\% of bug reports lack these elements.},
  journal = {Empir. Softw. Eng.},
  publisher = {Springer Science and Business Media LLC},
  volume = {25},
  number = {6},
  pages = {5255--5294},
  month = nov,
  year = {2020},
  copyright = {https://creativecommons.org/licenses/by/4.0}
}

@article{Spinellis2018,
  doi = {10.1145/3186278},
  title = {Modern debugging},
  author = {Spinellis, Diomidis},
  journal = {Commun. ACM},
  publisher = {Association for Computing Machinery (ACM)},
  volume = {61},
  number = {11},
  pages = {124--134},
  month = oct,
  year = {2018},
  copyright = {http://www.acm.org/publications/policies/copyright\_policy\#Background},
  abstract = {}
}

@misc{Stokes2022,
  author = {Chase Stokes and Marti Hearst},
  title = {Why More Text is (Often) Better: Themes from Reader Preferences for Integration of Charts and Text},
  year = {2022},
  eprint = {arXiv:2209.10789},
}

@inproceedings{Storey2022,
  doi = {10.1145/3528579.3529177},
  title = {How developers and managers define and trade productivity for quality},
  booktitle = chase,
  author = {Storey, Margaret-Anne and Houck, Brian and Zimmermann, Thomas},
  publisher = {ACM},
  month = may,
  year = {2022},
  conference = icse,
  abstract = {Background: Developer productivity and software quality are different but related multi-dimensional lenses into the software engineering process. The terms are used liberally in industry settings, but there is a lack of consensus and awareness of what these terms mean in specific contexts and which trade-offs should be considered. Objective \& Method: Through an exploratory survey study with developers and managers at Microsoft, we investigated how these cohorts define productivity and quality, how aligned they are in their views, how aware they are of other views, and if and how they trade quality for productivity. Results: We find developers and managers, as cohorts, are not well-aligned in their views of productivity–developers think more about work activities, while more managers consider performance or quality outcomes. We find developers and managers have more aligned views of what quality means, with the majority defining quality in terms of robustness, while the timely delivery of evolvable features that delight users are also key quality aspects. Over half of the developers and managers we surveyed make productivity and quality trade-offs but with good reasons for doing so. Conclusion: Alignment on how developers and managers define productivity and quality is essential if they are to design effective improvement interventions and meaningful metrics to measure productivity and quality improvements. Our research provides a frame for developers and managers to align their views and to make informed decisions on productivity and quality trade-offs.}
}

@article{Strode2022,
  doi = {10.1007/s10664-021-10115-0},
  title = {A teamwork effectiveness model for agile software development},
  author = {Strode, Diane and Dings{\o}yr, Torgeir and Lindsjorn, Yngve},
  abstract = {AbstractTeamwork is crucial in software development, particularly in agile development teams which are cross-functional and where team members work intensively together to develop a cohesive software solution. Effective teamwork is not easy; prior studies indicate challenges with communication, learning, prioritization, and leadership. Nevertheless, there is much advice available for teams, from agile methods, practitioner literature, and general studies on teamwork to a growing body of empirical studies on teamwork in the specific context of agile software development. This article presents the agile teamwork effectiveness model (ATEM) for colocated agile development teams. The model is based on evidence from focus groups, case studies, and multi-vocal literature and is a revision of a general team effectiveness model. Our model of agile teamwork effectiveness is composed of shared leadership, team orientation, redundancy, adaptability, and peer feedback. Coordinating mechanisms are needed to facilitate these components. The coordinating mechanisms are shared mental models, communication, and mutual trust. We critically examine the model and discuss extensions for very small, multi-team, distributed, and safety-critical development contexts. The model is intended for researchers, team members, coaches, and leaders in the agile community.},
  journal = {Empir. Softw. Eng.},
  publisher = {Springer Science and Business Media LLC},
  volume = {27},
  number = {2},
  month = mar,
  year = {2022},
  copyright = {https://creativecommons.org/licenses/by/4.0}
}

@comment{TTT}

@misc{Tan2022,
  author = {Wen Siang Tan and Markus Wagner and Christoph Treude},
  title = {Detecting Outdated Code Element References in Software Repository Documentation},
  year = {2022},
  eprint = {arXiv:2212.01479},
}

@inproceedings{Tian2022,
  doi = {10.1145/3510003.3510205},
  title = {What makes a good commit message?},
  booktitle = icse,
  author = {Tian, Yingchen and Zhang, Yuxia and Stol, Klaas-Jan and Jiang, Lin and Liu, Hui},
  publisher = {ACM},
  month = may,
  year = {2022},
  conference = icse,
  abstract = {A key issue in collaborative software development is communication among developers. One modality of communication is a commit message, in which developers describe the changes they make in a repository. As such, commit messages serve as an “audit trail” by which developers can understand how the source code of a project has changed-and why. Hence, the quality of commit messages affects the effectiveness of communication among developers. Commit messages are often of poor quality as developers lack time and motivation to craft a good message. Several automatic approaches have been proposed to generate commit messages. However, these are based on uncurated datasets including considerable proportions of poorly phrased commit messages. In this multi-method study, we first define what constitutes a “good” commit message, and then establish what proportion of commit messages lack information using a sample of almost 1,600 messages from five highly active open source projects. We find that an average of circa 44\% of messages could be improved, suggesting the use of uncurated datasets may be a major threat when commit message generators are trained with such data. We also observe that prior work has not considered semantics of commit messages, and there is surprisingly little guidance available for writing good commit messages. To that end, we develop a taxonomy based on recurring patterns in commit messages' expressions. Finally, we investigate whether “good” commit messages can be automatically identified; such automation could prompt developers to write better commit messages.}
}

@article{Timperley2021,
  doi = {10.1007/s10664-021-09973-5},
  url = {https://doi.org/10.1007/s10664-021-09973-5},
  year = {2021},
  month = may,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {26},
  number = {4},
  author = {Christopher S. Timperley and Lauren Herckis and Claire Le Goues and Michael Hilton},
  title = {Understanding and improving artifact sharing in software engineering research},
  journal = {Empirical Software Engineering}
}

@article{Tissenbaum2021,
  doi = {10.1111/bjet.13072},
  title = {The case for alternative endpoints in computing education},
  author = {Tissenbaum, Mike and Weintrop, David and Holbert, Nathan and Clegg, Tamara},
  journal = {Br. J. Educ. Technol.},
  publisher = {Wiley},
  volume = {52},
  number = {3},
  pages = {1164--1177},
  month = may,
  year = {2021},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  abstract = {This paper argues for a reexamination of the nature and goals of broad computing education initiatives. Instead of starting with specific values or goals, we instead begin by considering various desired endpoints of computing instruction and then work backward to reason about what form learning activities might take and what are the underlying values and principles that support learners in reaching these endpoints. The result of this exercise is a push for rethinking the form of contemporary computing education with an eye toward more diverse, equitable and meaningful endpoints. With a focus on the role that constructionistfocused pedagogies and designs can play in supporting these endpoints, we examine four distinct cases and the endpoints they support. This paper is not intended to encompass all the possible alternate endpoints for computer science education; rather, this work seeks to start a conversation around the nature of and need for alternate endpoints, as a means to reevaluate the current tools and curricula to prepare learners for a future of active and empowered computingliterate citizens.}
}

@inproceedings{Truong2022,
  doi = {10.1145/3524842.3528488},
  title = {The unsolvable problem or the unheard answer?},
  booktitle = msr,
  author = {Truong, Kimberly and Miller, Courtney and Vasilescu, Bogdan and K{\"a}stner, Christian},
  publisher = {ACM},
  month = may,
  year = {2022},
  abstract = {Talks at practitioner-focused open-source software conferences are a valuable source of information for software engineering researchers. They provide a pulse of the community and are valuable source material for grey literature analysis. We curated a dataset of 24,669 talks from 87 open-source conferences between 2010 and 2021. We stored all relevant metadata from these conferences and provide scripts to collect the transcripts. We believe this data is useful for answering many kinds of questions, such as: What are the important/highly discussed topics within practitioner communities? How do practitioners interact? And how do they present themselves to the public? We demonstrate the usefulness of this data by reporting our findings from two small studies: a topic model analysis providing an overview of open-source community dynamics since 2011 and a qualitative analysis of a smaller community-oriented sample within our dataset to gain a better understanding of why contributors leave open-source software.}
}

@inproceedings{Tshukudu2020,
  doi = {10.1145/3372782.3406270},
  title = {Understanding conceptual transfer for students learning new programming languages},
  booktitle = icer,
  author = {Tshukudu, Ethel and Cutts, Quintin},
  publisher = {ACM},
  month = aug,
  year = {2020},
  conference = icer,
  abstract = {Prior research has shown that students face transition challenges between programming languages (PL) over the course of their education. We could not find research attempting to devise a model that describes the transition process and how students' learning of programming concepts is affected during the shift. In this paper, we propose a model to describe PL transfer for relative novices. In the model, during initial stages of learning a new language, students will engage in learning three categories of concepts, True Carryover Concepts, False Carryover Concepts, or Abstract True Carryover Concepts; during the transition, learners automatically effect a transfer of semantics between languages based on syntax matching. In order to find support for the model, we conducted two empirical studies. Study 1 investigated near-novice undergraduate students transitioning from procedural Python to object-oriented Java while Study 2 investigated near-novice postgraduate students doing a transfer from object-oriented Java to procedural Python. Results for both studies indicate that students had little or no difficulty with transitioning on TCC due to positive semantic transfer based on syntax similarities while they had the most difficulty transitioning on FCC due to negative semantic transfer. Students had little or no semantic transfer on ATCC due to differences in syntax between the languages. We suggest ways in which the model can inform pedagogy on how to ease the transition process.}
}

@inproceedings{Tuna2022,
  doi = {10.1145/3510457.3513080},
  title = {Bug tracking process smells in practice},
  booktitle = icse,
  author = {Tuna, Erdem and Kovalenko, Vladimir and T{\"u}z{\"u}n, Eray},
  publisher = {ACM},
  month = may,
  year = {2022},
  conference = icse,
  abstract = {Software teams use bug tracking (BT) tools to report and manage bugs. Each record in a bug tracking system (BTS) is a reporting entity consisting of several information fields. The contents of the reports are similar across different tracking tools, though not the same. The variation in the workflow between teams prevents defining an ideal process of running BTS. Nevertheless, there are best practices reported both in white and gray literature. Developer teams may not adopt the best practices in their BT process. This study investigates the non-compliance of developers with best practices, so-called smells, in the BT process. We mine bug reports of four projects in the BTS of JetBrains, a software company, to observe the prevalence of BT smells in an industrial setting. Also, we survey developers to see (1) if they recognize the smells, (2) their perception of the severity of the smells, and (3) the potential benefits of a BT process smell detection tool. We found that (1) smells occur, and their detection requires a solid understanding of the BT practices of the projects, (2) smell severity perception varies across smell types, and (3) developers considered that a smell detection tool would be useful for six out of the 12 smell categories.}
}

@article{Turk2021,
  doi = {10.1002/spe.3027},
  url = {https://doi.org/10.1002/spe.3027},
  year = {2021},
  month = sep,
  publisher = {Wiley},
  volume = {52},
  number = {2},
  pages = {415--426},
  author = {Toma{\v{z}} Turk},
  title = {{SDFunc}: Modular spreadsheet design with sheet-defined functions in Microsoft Excel},
  journal = {Software: Practice and Experience},
  abstract = {The goal of the SDFunc tool is to enable spreadsheet developers to build their model computations in Microsoft Excel according to the modular design approach, that is, the separation of the functionalities into independent, interchangeable modules with interfaces that provide input and output elements. This concept has been theoretically developed in recent years and is known as sheet-defined functions in the literature. In this article, we are presenting our implementation of the tool and the evaluation steps that we took to make the tool interesting and suitable for the assessment of the modular approach in spreadsheet development by the industry, specifically within organizational and companies' settings where the spreadsheet developers and end-users involved in experiments expect to use a well-established spreadsheet platform. We also demonstrated that sheet-defined functions can be implemented by development tools already present in Microsoft Excel.}
}

@comment{UUU}

@comment{VVV}

@inproceedings{Vidoni2021,
  doi = {10.1109/icse43902.2021.00136},
  url = {https://doi.org/10.1109/icse43902.2021.00136},
  year = {2021},
  month = may,
  publisher = {{IEEE}},
  author = {Melina Vidoni},
  title = {Evaluating Unit Testing Practices in R Packages},
  booktitle = {2021 {IEEE}/{ACM} 43rd International Conference on Software Engineering ({ICSE})},
  abstract = {"Testing Technical Debt (TTD) occurs due to shortcuts (non-optimal decisions) taken about testing; it is the test dimension of technical debt. R is a package-based programming ecosystem that provides an easy way to install third-party code, datasets, tests, documentation and examples. This structure makes it especially vulnerable to TTD because errors present in a package can transitively affect all packages and scripts that depend on it. Thus, TTD can effectively become a threat to the validity of all analysis written in R that rely on potentially faulty code. This two-part study provides the first analysis in this area. First, 177 systematically-selected, open-source R packages were mined and analysed to address quality of testing, testing goals, and identify potential TTD sources. Second, a survey addressed how R package developers perceive testing and face its challenges (response rate of 19.4\%). Results show that testing in R packages is of low quality; the most common smells are inadequate and obscure unit testing, improper asserts, inexperienced testers and improper test design. Furthermore, skilled R developers still face challenges such as time constraints, emphasis on development rather than testing, poor tool documentation and a steep learning curve."}
}

@article{Vidoni2022,
  doi = {10.1016/j.jss.2022.111265},
  url = {https://doi.org/10.1016/j.jss.2022.111265},
  year = {2022},
  month = jun,
  publisher = {Elsevier {BV}},
  volume = {188},
  pages = {111265},
  author = {Melina Vidoni},
  title = {Understanding Roxygen package documentation in R},
  journal = {Journal of Systems and Software},
  abstract = {R is a package-based programming ecosystem that provides an easy way to install third-party code, datasets, and examples. Thus, R developers rely heavily on the documentation of the packages they import to use them correctly and accurately. This documentation is often written using Roxygen, equivalent to Java's well-known Javadoc. This two-part study provides the first analysis in this area. First, 379 systematically-selected, open-source R packages were mined and analysed to address the quality of their documentation in terms of presence, distribution, and completeness to identify potential sources of documentation debt of technical debt that describes problems in the documentation. Second, a survey addressed how R package developers perceive documentation and face its challenges (with a response rate of 10.04\%). Results show that incomplete documentation is the most common smell, with several cases of incorrect use of the Roxygen utilities. Unlike in traditional API documentation, developers do not focus on how behaviour is implemented but on common use cases and parameter documentation. Respondents considered the examples section the most useful, and commonly perceived challenges were unexplained examples, ambiguity, incompleteness and fragmented information.}
}

@comment{WWW}

@article{Wang2020b,
  doi = {10.1145/3387111},
  title = {Unveiling elite developers' activities in open source projects},
  author = {Wang, Zhendong and Feng, Yang and Wang, Yi and Jones, James A and Redmiles, David},
  journal = {ACM Trans. Softw. Eng. Methodol.},
  publisher = {Association for Computing Machinery (ACM)},
  volume = {29},
  number = {3},
  pages = {1--35},
  month = jul,
  year = {2020},
  abstract = {Open source developers, particularly the elite developers who own the administrative privileges for a project, maintain a diverse portfolio of contributing activities. They not only commit source code but also exert significant efforts on other communicative, organizational, and supportive activities. However, almost all prior research focuses on specific activities and fails to analyze elite developers’ activities in a comprehensive way. To bridge this gap, we conduct an empirical study with fine-grained event data from 20 large open source projects hosted on GITHUB. We investigate elite developers’ contributing activities and their impacts on project outcomes. Our analyses reveal three key findings: (1) elite developers participate in a variety of activities, of which technical contributions (e.g., coding) only account for a small proportion; (2) as the project grows, elite developers tend to put more effort into supportive and communicative activities and less effort into coding; and (3) elite developers’ efforts in nontechnical activities are negatively correlated with the project’s outcomes in terms of productivity and quality in general, except for a positive correlation with the bug fix rate (a quality indicator). These results provide an integrated view of elite developers’ activities and can inform an individual’s decision making about effort allocation, which could lead to improved project outcomes. The results also provide implications for supporting these elite developers.}
}

@article{Wolter2022,
  doi = {10.1145/3571852},
  url = {https://doi.org/10.1145/3571852},
  year = {2022},
  month = dec,
  publisher = {Association for Computing Machinery ({ACM})},
  author = {Thomas Wolter and Ann Barcomb and Dirk Riehle and Nikolay Harutyunyan},
  title = {Open Source License Inconsistencies on {GitHub}},
  journal = {{ACM} Transactions on Software Engineering and Methodology}
}

@misc{Wyrich2022,
  author = {Marvin Wyrich and Justus Bogner and Stefan Wagner},
  title = {40 Years of Designing Code Comprehension Experiments: A Systematic Mapping Study},
  year = {2022},
  eprint = {arXiv:2206.11102},
}

@comment{XXX}

@comment{YYY}

@inproceedings{Young2021,
  doi = {10.1109/msr52588.2021.00036},
  url = {https://doi.org/10.1109/msr52588.2021.00036},
  year = {2021},
  month = may,
  publisher = {{IEEE}},
  author = {Jean-Gabriel Young and Amanda Casari and Katie McLaughlin and Milo Z. Trujillo and Laurent Hebert-Dufresne and James P. Bagrow},
  title = {Which contributions count? Analysis of attribution in open source},
  booktitle = msr,
  abstract = {Open source software projects usually acknowledge contributions with text files, websites, and other idiosyncratic methods. These data sources are hard to mine, which is why contributorship is most frequently measured through changes to repositories, such as commits, pushes, or patches. Recently, some open source projects have taken to recording contributor actions with standardized systems; this opens up a unique opportunity to understand how community-generated notions of contributorship map onto codebases as the measure of contribution. Here, we characterize contributor acknowledgment models in open source by analyzing thousands of projects that use a model called All Contributors to acknowledge diverse contributions like outreach, finance, infrastructure, and community management. We analyze the life cycle of projects through this model's lens and contrast its representation of contributorship with the picture given by other methods of acknowledgment, including GitHub's top committers indicator and contributions derived from actions taken on the platform. We find that community-generated systems of contribution acknowledgment make work like idea generation or bug finding more visible, which generates a more extensive picture of collaboration. Further, we find that models requiring explicit attribution lead to more clearly defined boundaries around what is and is not a contribution.}
}

@comment{ZZZ}

@misc{Zakaria2022,
  author = {Farid Zakaria and Thomas R. W. Scogland and Todd Gamblin and Carlos Maltzahn},
  title = {Mapping Out the HPC Dependency Chaos},
  year = {2022},
  eprint = {arXiv:2211.05118},
}

@article{Zerouali2021,
  doi = {10.1016/j.scico.2021.102653},
  url = {https://doi.org/10.1016/j.scico.2021.102653},
  year = {2021},
  month = jul,
  publisher = {Elsevier {BV}},
  volume = {207},
  pages = {102653},
  author = {Ahmed Zerouali and Tom Mens and Coen De Roover},
  title = {On the usage of {JavaScript}, Python and Ruby packages in Docker Hub images},
  journal = {Science of Computer Programming},
  abstract = {Docker is one of the most popular containerization technologies. A Docker container can be saved into an image including all environmental packages required to run it, such as system and third-party packages from language-specific package repositories. Relying on its modularity, an image can be shared and included in other images to simplify the way of building and packaging new software. However, some package managers allow to include duplicated packages in an image, increasing its footprint; and outdated packages may miss new features and bug fixes or contain reported security vulnerabilities, putting the image in which they are contained at risk. Previous research has focused on studying operating system packages within Docker images, but little attention has been given to third-party packages. This article empirically studies installation practices, outdatedness and vulnerabilities of JavaScript, Python and Ruby packages installed in 3,000 popular community Docker Hub images.  In many cases, these installed packages missed important releases leading to potential vulnerabilities of the images. Our findings suggest that maintainers of Docker Hub community images should invest more effort in updating outdated packages contained in those images in order to significantly reduce the number of vulnerabilities. In addition to this, Python community images are generally much less outdated and much less subject to vulnerabilities than NodeJS and Ruby community images. Specifically for NodeJS community images, elimination of duplicate package releases could lead to a significant reduction in their image footprint.}
}

@inproceedings{Zhang2022a,
  doi = {10.1145/3522664.3528620},
  title = {Code smells for machine learning applications},
  booktitle = {Proceedings of the 1st International Conference on {AI} Engineering: Software Engineering for {AI}},
  author = {Zhang, Haiyin and Cruz, Lu{\'\i}s and van Deursen, Arie},
  publisher = {ACM},
  month = may,
  year = {2022},
  conference = {CAIN '22: 1st Conference on AI Engineering - Software Engineering for AI},
  abstract = {The popularity of machine learning has wildly expanded in recent years. Machine learning techniques have been heatedly studied in academia and applied in the industry to create business value. However, there is a lack of guidelines for code quality in machine learning applications. In particular, code smells have rarely been studied in this domain. Although machine learning code is usually integrated as a small part of an overarching system, it usually plays an important role in its core functionality. Hence ensuring code quality is quintessential to avoid issues in the long run. This paper proposes and identifies a list of 22 machine learning-specific code smells collected from various sources, including papers, grey literature, GitHub commits, and Stack Overflow posts. We pinpoint each smell with a description of its context, potential issues in the long run, and proposed solutions. In addition, we link them to their respective pipeline stage and the evidence from both academic and grey literature. The code smell catalog helps data scientists and developers produce and maintain high-quality machine learning application code.}
}

@misc{Zhang2022b,
  author = {Kaiwen Zhang and Guanjun Liu},
  title = {Automatically Transform Rust Source to Petri Nets for Checking Deadlocks},
  year = {2022},
  eprint = {arXiv:2212.02754},
}

@article{Zhang2022c,
  doi = {10.1145/3510849},
  url = {https://doi.org/10.1145/3510849},
  year = {2022},
  month = oct,
  publisher = {Association for Computing Machinery ({ACM})},
  volume = {31},
  number = {4},
  pages = {1--24},
  author = {Yuxia Zhang and Hui Liu and Xin Tan and Minghui Zhou and Zhi Jin and Jiaxin Zhu},
  title = {Turnover of Companies in {OpenStack}: Prevalence and Rationale},
  journal = {{ACM} Transactions on Software Engineering and Methodology}
}

@article{Zheng2019,
  doi = {10.1016/j.jss.2019.02.025},
  title = {Towards understanding bugs in an open source cloud management stack: An empirical study of {OpenStack} software bugs},
  author = {Zheng, Wei and Feng, Chen and Yu, Tingting and Yang, Xibing and Wu, Xiaoxue},
  journal = {J. Syst. Softw.},
  publisher = {Elsevier BV},
  volume = {151},
  pages = {210--223},
  month = may,
  year = {2019},
  abstract = {}
}

@article{Zhou2019,
  doi = {10.1007/s10664-019-09744-3},
  url = {https://doi.org/10.1007/s10664-019-09744-3},
  year = {2019},
  month = jul,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {25},
  number = {1},
  pages = {139--177},
  author = {Jiayuan Zhou and Shaowei Wang and Cor-Paul Bezemer and Ahmed E. Hassan},
  title = {Bounties on technical Q{\&}A sites: a case study of Stack Overflow bounties},
  journal = {Empirical Software Engineering}
}

@inproceedings{Zhu2022,
  doi = {10.1145/3510003.3510164},
  url = {https://doi.org/10.1145/3510003.3510164},
  year = {2022},
  month = may,
  publisher = {{ACM}},
  author = {Shuofei Zhu and Ziyi Zhang and Boqin Qin and Aiping Xiong and Linhai Song},
  title = {Learning and programming challenges of rust},
  booktitle = {Proceedings of the 44th International Conference on Software Engineering}
}
